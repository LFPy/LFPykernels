{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a709c4-758d-468a-b64b-e42f7a76ef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113ac894-f45f-402f-8d8d-f144a6479bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from parameters import ParameterSpace, ParameterRange, ParameterSet\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib import colors\n",
    "import h5py\n",
    "import scipy.signal as ss\n",
    "from hay2011_network_parameters import (networkParameters, population_names,\n",
    "                                        population_sizes)\n",
    "from lfpykernels import KernelApprox, GaussCylinderPotential\n",
    "from lfpykernels import KernelApproxCurrentDipoleMoment as CurrentDipoleMoment\n",
    "import neuron\n",
    "import example_network_methods as methods\n",
    "import hay2011_network_parameters as params\n",
    "import scipy.stats as st\n",
    "from copy import deepcopy\n",
    "from plotting import draw_lineplot, annotate_subplot\n",
    "import plotting\n",
    "# from lfpykit import CurrentDipoleMoment, LaminarCurrentSourceDensity\n",
    "import json\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from time import time\n",
    "import neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdf2ee7-6da7-45ff-a6f2-104a1f87fdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update(plotting.rcParams)\n",
    "golden_ratio = plotting.golden_ratio\n",
    "figwidth = plotting.figwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aede24-0c3d-49bd-95b0-bbf30dab68d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PS0 = ParameterSpace('Hay2011_PS0.txt')\n",
    "PS1 = ParameterSpace('Hay2011_PS1.txt')\n",
    "PS2 = ParameterSpace('Hay2011_PS2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c264918-3f6d-4754-a8a3-095f1535cd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron.load_mechanisms('mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff85978-85ed-4196-9c34-4e551924d3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSIENT = 2000\n",
    "dt = networkParameters['dt']\n",
    "tau = 100  # max time lag relative to spike for kernel predictions\n",
    "tau_trunc = 50 # max time lag for shown in plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1bf9c3-5872-4db2-8d70-7c0a5f9978e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.mlab.psd/csd settings\n",
    "Fs = 1000 / dt\n",
    "NFFT = 1024\n",
    "noverlap = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81d7e90-4231-4566-b84e-1bbf195ab8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# low-pass filter settings\n",
    "N = 2  # filter order\n",
    "rp = 0.1  # ripple in passband (dB)\n",
    "rs = 40.  # minimum attenuation required in the stop band (dB)\n",
    "fc = 100.  # critical frequency (Hz)\n",
    "\n",
    "# filter coefficients on 'sos' format\n",
    "sos_ellip = ss.ellip(N=N, rp=rp, rs=rs, Wn=fc, btype='lp', fs=Fs, output='sos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e13095-62b2-4cda-86e5-3a74e66372be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not investigate models with biophys='lin'\n",
    "PS2['biophys'] = ParameterRange(['frozen'])\n",
    "PS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c291d412-4c85-454c-b622-56a038c140fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define iterable parameter space for nu_X&nu_ext (relative scaling) and V_rest (offset)\n",
    "PS3 = ParameterSpace(\n",
    "    dict(\n",
    "        nu_X_scaling=ParameterRange(np.linspace(0., 2., 21)),\n",
    "        V_rest_offset=ParameterRange(np.linspace(-15., 15., 21)),\n",
    "    )\n",
    ")\n",
    "PS3, PS3.num_conditions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4606ba54-77e2-4c52-b71e-f41f2f6a5914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out which real LFP to compare with\n",
    "for pset in PS1.iter_inner():\n",
    "    weight_EE = pset['weight_EE']\n",
    "    weight_IE = pset['weight_IE']\n",
    "    weight_EI = pset['weight_EI']\n",
    "    weight_II = pset['weight_II']\n",
    "    weight_scaling = pset['weight_scaling']\n",
    "    pset_0 = ParameterSet(dict(weight_EE=weight_EE,\n",
    "                               weight_IE=weight_IE,\n",
    "                               weight_EI=weight_EI,\n",
    "                               weight_II=weight_II,\n",
    "                               weight_scaling=weight_scaling,\n",
    "                               n_ext=PS0['n_ext'].value))\n",
    "    js_0 = json.dumps(pset_0, sort_keys=True).encode()\n",
    "    md5_0 = hashlib.md5(js_0).hexdigest()\n",
    "    OUTPUTPATH_REAL = os.path.join('output', md5_0)\n",
    "\n",
    "    break\n",
    "print(f'comparing with ground truth dataset: {OUTPUTPATH_REAL}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90546643-588a-4dd7-80d1-f591c83571d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average firing rate of presynaptic populations X\n",
    "mean_nu_X = methods.compute_mean_nu_X(params, OUTPUTPATH_REAL,\n",
    "                                 TRANSIENT=TRANSIENT)\n",
    "mean_nu_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04eecce-adef-45a2-afb2-8f99468509cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract median soma voltages from actual network simulation and\n",
    "# assume this value corresponds to Vrest.\n",
    "Vrest_Y = {}\n",
    "with h5py.File(os.path.join(OUTPUTPATH_REAL, 'somav.h5'\n",
    "                            ), 'r') as f:\n",
    "    for Y in params.population_names:\n",
    "        Vrest_Y[Y] = np.median(f[Y][()][:, TRANSIENT:])\n",
    "Vrest_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2998a7ab-77aa-429c-9854-a70c0591fd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute firing rate time series of \"real\" network (as spikes per time bin of width dt)\n",
    "nu_X = dict()\n",
    "tstop = networkParameters['tstop']\n",
    "bins = (np.arange(0, tstop / dt + 2)\n",
    "        * dt - dt / 2)\n",
    "with h5py.File(os.path.join(OUTPUTPATH_REAL, 'spikes.h5'), 'r') as f:\n",
    "    for i, X in enumerate(params.population_names):\n",
    "        hist = np.histogram(np.concatenate(f[X]['times']), bins=bins)[0]\n",
    "        nu_X[X] = hist.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fb7c14-781c-4cad-ab41-31263764ed49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth dataset for comparison\n",
    "probe = 'CurrentDipoleMoment'\n",
    "with h5py.File(os.path.join(OUTPUTPATH_REAL, f'{probe}.h5'),\n",
    "               'r') as f:\n",
    "    data_gt = f['data']['imem'][-1, ]\n",
    "\n",
    "# low pass filter\n",
    "data_gt_lp = ss.sosfiltfilt(sos_ellip, data_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f80f4b-6ebf-41c9-a62b-6425b9b74572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precompute standard deviations\n",
    "data_gt_std = data_gt[int(TRANSIENT // dt):].std()\n",
    "data_gt_lp_std = data_gt_lp[int(TRANSIENT // dt):].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e6abf8-2fc8-4947-a1fa-6996a2e7d839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spike-dipole moment kernel approximations\n",
    "# obtained using the KernelApprox class\n",
    "\n",
    "# kernel container\n",
    "H_YX_pred = dict()\n",
    "for k, pset in enumerate(PS2.iter_inner()):\n",
    "    for pset_inner in PS3.iter_inner():\n",
    "        # sorted json dictionary\n",
    "        pset = {**pset, **pset_inner}  # merge dicts\n",
    "        js = json.dumps(pset, sort_keys=True).encode()\n",
    "        md5 = hashlib.md5(js).hexdigest()\n",
    "\n",
    "        # parameters\n",
    "        weight_EE = pset['weight_EE']\n",
    "        weight_IE = pset['weight_IE']\n",
    "        weight_EI = pset['weight_EI']\n",
    "        weight_II = pset['weight_II']\n",
    "        weight_scaling = pset['weight_scaling']\n",
    "        biophys = pset['biophys']\n",
    "        n_ext = pset['n_ext']\n",
    "        g_eff = pset['g_eff']\n",
    "\n",
    "        t_X = TRANSIENT  # presynaptic activation time\n",
    "        \n",
    "\n",
    "        # synapse max. conductance (function, mean, st.dev., min.):\n",
    "        weights = np.array([[weight_EE, weight_IE],\n",
    "                            [weight_EI, weight_II]]) * weight_scaling\n",
    "\n",
    "\n",
    "        # set up recording of current dipole moments.\n",
    "        current_dipole_moment = CurrentDipoleMoment(cell=None)\n",
    "\n",
    "        # create rescaled nu_X parameter for KernelApprox class\n",
    "        nu_X_scaled = {}\n",
    "        for X in params.population_names:\n",
    "            nu_X_scaled.update({X:mean_nu_X[X] * pset['nu_X_scaling']})\n",
    "\n",
    "\n",
    "        # kernel container\n",
    "        H_YX_pred[md5] = dict()\n",
    "\n",
    "        for i, (X, N_X) in enumerate(zip(params.population_names,\n",
    "                                         params.population_sizes)):\n",
    "            for j, (Y, N_Y) in enumerate(zip(params.population_names,\n",
    "                                                         params.population_sizes)):\n",
    "                # set up cell parameters\n",
    "                cellParameters = deepcopy(params.cellParameters[Y])\n",
    "                if biophys == 'frozen':\n",
    "                    if Y == 'E':\n",
    "                        cellParameters.update({\n",
    "                            'templatefile': [\n",
    "                                'L5bPCmodelsEH/models/L5PCbiophys3_frozen.hoc',\n",
    "                                'L5bPCmodelsEH/models/L5PCtemplate_frozen.hoc'\n",
    "                                ],\n",
    "                            'templatename': 'L5PCtemplate_frozen',\n",
    "                            'custom_fun': [\n",
    "                                methods.set_V_R,\n",
    "                                methods.make_cell_uniform\n",
    "                                ],\n",
    "                            'custom_fun_args': [dict(Vrest=Vrest_Y[Y] + pset['V_rest_offset'])] * 2,\n",
    "                        })\n",
    "                    elif Y == 'I':\n",
    "                        cellParameters.update({\n",
    "                            'custom_fun': [\n",
    "                                methods.set_frozen_hay2011,\n",
    "                                methods.make_cell_uniform\n",
    "                                ],\n",
    "                            'custom_fun_args': [dict(Vrest=Vrest_Y[Y] + pset['V_rest_offset'])] * 2,\n",
    "                        })\n",
    "                    else:\n",
    "                        raise Exception(f'population {Y} not recognized')\n",
    "                elif biophys == 'lin':\n",
    "                    if Y == 'E':\n",
    "                        cellParameters.update({\n",
    "                            'templatefile': [\n",
    "                                'L5bPCmodelsEH/models/L5PCbiophys3_lin.hoc',\n",
    "                                'L5bPCmodelsEH/models/L5PCtemplate_lin.hoc'\n",
    "                                ],\n",
    "                            'templatename': 'L5PCtemplate_lin',\n",
    "                            'custom_fun': [\n",
    "                                methods.set_V_R,\n",
    "                                methods.make_cell_uniform\n",
    "                                ],\n",
    "                            'custom_fun_args': [dict(Vrest=Vrest_Y[Y] + pset['V_rest_offset'])] * 2,\n",
    "                        })\n",
    "                    elif Y == 'I':\n",
    "                        cellParameters.update({\n",
    "                            'custom_fun': [\n",
    "                                methods.set_Ih_linearized_hay2011,\n",
    "                                methods.make_cell_uniform\n",
    "                                ],\n",
    "                            'custom_fun_args': [dict(Vrest=Vrest_Y[Y] + pset['V_rest_offset'])] * 2,\n",
    "                        })\n",
    "                    else:\n",
    "                        raise Exception(f'population {Y} not recognized')\n",
    "                elif biophys == 'pas':\n",
    "                    if Y == 'E':\n",
    "                        cellParameters.update({\n",
    "                            'templatefile': [\n",
    "                                'L5bPCmodelsEH/models/L5PCbiophys3_pas.hoc',\n",
    "                                'L5bPCmodelsEH/models/L5PCtemplate_pas.hoc'\n",
    "                                ],\n",
    "                            'templatename': 'L5PCtemplate_pas',\n",
    "                            'custom_fun': [\n",
    "                                methods.make_cell_uniform\n",
    "                                ],\n",
    "                            'custom_fun_args': [dict(Vrest=Vrest_Y[Y] + pset['V_rest_offset'])],\n",
    "                        })\n",
    "                    elif Y == 'I':\n",
    "                        cellParameters.update({\n",
    "                            'custom_fun': [\n",
    "                                methods.set_pas_hay2011,\n",
    "                                methods.make_cell_uniform\n",
    "                                ],\n",
    "                            'custom_fun_args': [dict(Vrest=Vrest_Y[Y] + pset['V_rest_offset'])] * 2,\n",
    "                        })\n",
    "                    else:\n",
    "                        raise Exception(f'population {Y} not recognized')\n",
    "                else:\n",
    "                    raise NotImplementedError(f'biophys={biophys} not implemented')\n",
    "\n",
    "\n",
    "                # population parameters\n",
    "                populationParameters = deepcopy(params.populationParameters)\n",
    "                populationParameters['rotation_args'] = deepcopy(params.rotation_args[Y])\n",
    "                populationParameters['cell_args'] = cellParameters\n",
    "                \n",
    "\n",
    "                # some inputs must be lists\n",
    "                synapseParameters = [\n",
    "                    dict(weight=weights[ii][j],\n",
    "                         syntype='Exp2Syn',\n",
    "                         **params.synapseParameters[ii][j])\n",
    "                    for ii in range(len(params.population_names))]\n",
    "                synapsePositionArguments = [\n",
    "                    params.synapsePositionArguments[ii][j]\n",
    "                    for ii in range(len(params.population_names))]\n",
    "\n",
    "                \n",
    "                # Create kernel approximator object\n",
    "                kernel = KernelApprox(\n",
    "                    X=params.population_names,\n",
    "                    Y=Y,\n",
    "                    N_X=np.array(params.population_sizes),\n",
    "                    N_Y=N_Y,\n",
    "                    C_YX=np.array(params.connectionProbability[i]),\n",
    "                    cellParameters=cellParameters,\n",
    "                    populationParameters=populationParameters['pop_args'],\n",
    "                    rotationParameters=params.rotation_args[Y],\n",
    "                    multapseFunction=params.multapseFunction,\n",
    "                    multapseParameters=[params.multapseArguments[ii][j] for ii in range(len(params.population_names))],\n",
    "                    delayFunction=params.delayFunction,\n",
    "                    delayParameters=[params.delayArguments[ii][j] for ii in range(len(params.population_names))],\n",
    "                    synapseParameters=synapseParameters,\n",
    "                    synapsePositionArguments=synapsePositionArguments,\n",
    "                    extSynapseParameters=params.extSynapseParameters,\n",
    "                    nu_ext=1000. / params.netstim_interval * pset['nu_X_scaling'],\n",
    "                    n_ext=n_ext[j],\n",
    "                    nu_X=nu_X_scaled,\n",
    "                )\n",
    "\n",
    "                # make kernel predictions\n",
    "                H_YX_pred[md5]['{}:{}'.format(Y, X)] = kernel.get_kernel(\n",
    "                    probes=[current_dipole_moment],\n",
    "                    Vrest=Vrest_Y[Y] + pset['V_rest_offset'], dt=dt, X=X, t_X=t_X, tau=tau,\n",
    "                    g_eff=g_eff,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee963d13-ffb4-485d-88c9-a338a9c16576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel.get_kernel returns dict with keys corresponding to probe class name\n",
    "probe = 'KernelApproxCurrentDipoleMoment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2874ee70-752b-49a3-91dc-cf60be8842bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute R^2 and r_STD metrics between ground truth and approximated signals equal to sum_X sum_Y (nu_X * H_YX)\n",
    "\n",
    "# container\n",
    "df = pd.DataFrame(columns=['md5', 'R2', 'r_STD', 'signal'])\n",
    "\n",
    "for k, pset in enumerate(PS2.iter_inner()):\n",
    "    for pset_inner in PS3.iter_inner():\n",
    "        # sorted json dictionary\n",
    "        pset = {**pset, **pset_inner}  # merge dicts\n",
    "        js = json.dumps(pset, sort_keys=True).encode()\n",
    "        md5 = hashlib.md5(js).hexdigest()\n",
    "        \n",
    "        # approximate signals using computed kernels\n",
    "        data = None\n",
    "        for X in population_names:\n",
    "            for Y in population_names:\n",
    "                if data is None:\n",
    "                    data = np.zeros(nu_X[X].size)\n",
    "                data = data + np.convolve(nu_X[X], H_YX_pred[md5]['{}:{}'.format(Y, X)][probe][-1, :], 'same')\n",
    "        # low pass filter\n",
    "        data_lp = ss.sosfiltfilt(sos_ellip, data)\n",
    "        \n",
    "        # Pearson correlation coefficients\n",
    "        Pcc = np.corrcoef(data_gt[int(TRANSIENT // dt):], \n",
    "                          data[int(TRANSIENT // dt):])[1:, :1].diagonal()\n",
    "        Pcc_lp = np.corrcoef(data_gt_lp[int(TRANSIENT // dt):],\n",
    "                             data_lp[int(TRANSIENT // dt):])[1:, :1].diagonal()\n",
    "\n",
    "        scaling = data[int(TRANSIENT  // dt):].std() / data_gt_std\n",
    "        scaling_lp = data_lp[int(TRANSIENT // dt):].std() / data_gt_lp_std\n",
    "\n",
    "        df = pd.concat([\n",
    "            df,\n",
    "            pd.DataFrame(\n",
    "                data={'md5': md5, 'R2': Pcc**2, 'r_STD': scaling, 'signal': 'raw'}, \n",
    "                index=[0]\n",
    "            ),\n",
    "            pd.DataFrame(\n",
    "                data={'md5': md5, 'R2': Pcc_lp**2, 'r_STD': scaling_lp, 'signal': 'LP'}, \n",
    "                index=[0]\n",
    "            ),\n",
    "            ], \n",
    "            ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3fce13-5a91-4bf6-a6a1-1123e4836eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot R2 and r_STD metrics as function of nu_X_scaling and V_rest_offset\n",
    "fig, axes = plt.subplots(PS2.num_conditions() * 2, 2, figsize=(figwidth / 2, figwidth / 2), sharex=True, sharey=True)\n",
    "fig.subplots_adjust(wspace=0.2)\n",
    "\n",
    "for i, ax in enumerate(axes[:, 0]):\n",
    "    annotate_subplot(ax, ncols=2, nrows=2, letter='ABCDEFGHIJ'[i], linear_offset=0.04)\n",
    "\n",
    "for pset in PS2.iter_inner():\n",
    "    \n",
    "    # containers for plotting\n",
    "    dim, keys = PS3.parameter_space_dimension_labels()\n",
    "    for k, metric in enumerate(['R2', 'r_STD']):\n",
    "        if metric == 'R2':\n",
    "            cmap = 'viridis'\n",
    "            norm = colors.Normalize(vmin=df[metric].min(), vmax=df[metric].max())\n",
    "        elif metric == 'r_STD':\n",
    "            cmap = 'RdBu_r'\n",
    "            def _forward(x): return np.log2(x)\n",
    "            def _inverse(x): return 2**x\n",
    "            norm = colors.FuncNorm((_forward, _inverse), vmin=0.25, vmax=4)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        metric_nice = '$R^2$' if metric == 'R2' else '$r_\\mathrm{STD}$'\n",
    "        \n",
    "        h = 0\n",
    "        for signal in ['raw', 'LP']:\n",
    "            imdata = np.zeros(dim)\n",
    "            for i, value_i in enumerate(PS3[keys[0]]):\n",
    "                for j, value_j in enumerate(PS3[keys[1]]):\n",
    "                    pset = {**pset, **{keys[0]: value_i, keys[1]:value_j}}  # merge dicts\n",
    "                    js = json.dumps(pset, sort_keys=True).encode()\n",
    "                    md5 = hashlib.md5(js).hexdigest()\n",
    "                    imdata[i, j] = df[(df['md5'].values==md5) & (df['signal'].values==signal)][metric].values\n",
    "            \n",
    "            \n",
    "            ax = axes[k, h]\n",
    "            \n",
    "            im = ax.pcolormesh(list(PS3[keys[1]]), list(PS3[keys[0]]), imdata, shading='auto', norm=norm, cmap=cmap)\n",
    "            # add a single contour line\n",
    "            if metric == 'R2':\n",
    "                levels = [0.75, 0.8, 0.85, 0.90]  # explained variance\n",
    "            else: \n",
    "                levels = [0.25, 0.5, 1, 2.0, 4.0]  # \n",
    "            CS = ax.contour(list(PS3[keys[1]]), list(PS3[keys[0]]), imdata, levels=levels, colors=['k'])\n",
    "            ax.clabel(CS, CS.levels, inline=True, fontsize=10)\n",
    "            \n",
    "            biophys = pset['biophys']\n",
    "            ax.set_title(f'{signal}')\n",
    "            cbar = plt.colorbar(im, ax=ax)\n",
    "            cbar.set_label(metric_nice)\n",
    "            if h == 0:\n",
    "                ax.set_ylabel(r'$\\overline{V}_\\mathrm{m}^\\diamond - \\overline{V}_\\mathrm{m}$ (mV)')\n",
    "            if k == 1:\n",
    "                cbar.set_ticks(levels)\n",
    "                cbar.set_ticklabels(levels)\n",
    "                cbar.set_label(metric_nice, labelpad=-10)\n",
    "                ax.set_xlabel(r'$\\langle \\nu_X^\\diamond \\rangle / \\langle \\nu_X \\rangle$ (-)')\n",
    "            h += 1\n",
    "\n",
    "fig.savefig(os.path.join('figures', 'figureS2.pdf'), bbox_inches='tight', pad_inches=0)\n",
    "fig.savefig(os.path.join('figures', 'figureS2.eps'), bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee0868b-4092-4a23-9cd9-05f66e6c3431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a87582c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('kernellfpy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "df590858b6b018e075a5c40b87c2081f6a2b114d97955d657b3e3f6005ad00da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
