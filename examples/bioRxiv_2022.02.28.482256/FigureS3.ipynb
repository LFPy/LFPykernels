{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0c883b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928c1790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from parameters import ParameterSpace, ParameterSet, ParameterRange\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import h5py\n",
    "import scipy.signal as ss\n",
    "from hay2011_network_parameters import (networkParameters, population_names,\n",
    "                                        population_sizes)\n",
    "from plotting import remove_axis_junk\n",
    "from lfpykernels import KernelApprox, GaussCylinderPotential\n",
    "import example_network_methods as methods\n",
    "import hay2011_network_parameters as params\n",
    "import scipy.stats as st\n",
    "from copy import deepcopy\n",
    "from plotting import draw_lineplot, annotate_subplot\n",
    "import plotting\n",
    "from lfpykit import CurrentDipoleMoment, LaminarCurrentSourceDensity\n",
    "import json\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df285b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update(plotting.rcParams)\n",
    "golden_ratio = plotting.golden_ratio\n",
    "figwidth = plotting.figwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa543452",
   "metadata": {},
   "outputs": [],
   "source": [
    "PS0 = ParameterSpace('hay2011_PS0.txt')\n",
    "PS1 = ParameterSpace('hay2011_PS1.txt')\n",
    "PS2 = ParameterSpace('hay2011_PS2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4753bb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore quasi-linearization\n",
    "PS2['biophys'] = ParameterRange(['frozen'])\n",
    "PS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8434f61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron.load_mechanisms('mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54ccf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSIENT = 2000\n",
    "dt = networkParameters['dt']\n",
    "tau = 100  # time lag relative to spike for kernel predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efbe45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ss.welch/plt.mlab.psd/csd settings\n",
    "Fs = 1000 / dt\n",
    "NFFT = 1024 * 2\n",
    "noverlap = 768 * 2\n",
    "detrend = False\n",
    "freqs_cutoff = 1000.  # (Hz) ignore freqs above this in spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d4674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# low-pass filter settings\n",
    "N = 2  # filter order\n",
    "rp = 0.1  # ripple in passband (dB)\n",
    "rs = 40.  # minimum attenuation required in the stop band (dB)\n",
    "fc = 100.  # critical frequency (Hz)\n",
    "\n",
    "# filter coefficients on 'sos' format\n",
    "sos_ellip = ss.ellip(N=N, rp=rp, rs=rs, Wn=fc, btype='lp', fs=Fs, output='sos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2313e5-1ac6-4ffe-8455-f0c8316e4f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# E and I colors\n",
    "colors = ['tab:blue', 'tab:red']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09069ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a ground truth parameterset list where 'weight_scaling' is varied\n",
    "# which is used to extract spike rates and ground truth signals\n",
    "for pset in PS1.iter_inner():\n",
    "    break\n",
    "pset['weight_scaling'] = PS0['weight_scaling']\n",
    "for key in ['biophys', 'i_syn', 'g_eff', 'perseg_Vrest']:\n",
    "    pset.pop(key)\n",
    "PS_ref = ParameterSpace(pset)\n",
    "\n",
    "for pset_ref in PS_ref.iter_inner():\n",
    "    js_ref = json.dumps(pset_ref, sort_keys=True).encode()\n",
    "    md5_ref = hashlib.md5(js_ref).hexdigest()\n",
    "    OUTPUTPATH_REF = os.path.join('output', md5_ref)\n",
    "    print(OUTPUTPATH_REF, os.path.isdir(OUTPUTPATH_REF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c7d2f6-cd25-49aa-86a8-11018b4573c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PS2['perseg_Vrest'] = ParameterRange([False, True])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fb513b56-040f-4fac-a28b-8d6f3db0d734",
   "metadata": {},
   "source": [
    "# flag; if True, use the median membrane potential per compartment for kernel predictions \n",
    "perseg_Vrest = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62114ca-43c5-4732-be0e-8fdf190f017e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(figwidth / 2, figwidth / 2))\n",
    "for hh, pset_ref in enumerate(PS_ref.iter_inner()):\n",
    "    js_ref = json.dumps(pset_ref, sort_keys=True).encode()\n",
    "    md5_ref = hashlib.md5(js_ref).hexdigest()\n",
    "    OUTPUTPATH_REF = os.path.join('output', md5_ref)\n",
    "    print(OUTPUTPATH_REF, os.path.isdir(OUTPUTPATH_REF))\n",
    "\n",
    "    for k, pset in enumerate(PS2.iter_inner()):\n",
    "        # parameters.\n",
    "        pset['weight_scaling'] = pset_ref['weight_scaling']  # use reference value!\n",
    "        \n",
    "        weight_EE = pset['weight_EE']\n",
    "        weight_IE = pset['weight_IE']\n",
    "        weight_EI = pset['weight_EI']\n",
    "        weight_II = pset['weight_II']\n",
    "        weight_scaling = pset['weight_scaling'] \n",
    "        biophys = pset['biophys']\n",
    "        n_ext = pset['n_ext']\n",
    "        g_eff = pset['g_eff']\n",
    "        perseg_Vrest = pset['perseg_Vrest']     \n",
    "\n",
    "        # sorted json dictionary\n",
    "        js = json.dumps(pset, sort_keys=True).encode()\n",
    "        md5 = hashlib.md5(js).hexdigest()\n",
    "\n",
    "        w = pset_ref['weight_scaling']\n",
    "        if w == 1.:\n",
    "            color = 'k'\n",
    "        else:\n",
    "            color = f'C{hh}'\n",
    "\n",
    "        \n",
    "        for i, (X, N_X) in enumerate(zip(params.population_names,\n",
    "                                         params.population_sizes)):\n",
    "            for j, (Y, N_Y) in enumerate(zip([params.population_names[0]], \n",
    "                                             [params.population_sizes[0]])):            \n",
    "                # Extract median soma voltages from actual network simulation and\n",
    "                # assume this value corresponds to Vrest.\n",
    "                if not perseg_Vrest:\n",
    "                    with h5py.File(os.path.join(OUTPUTPATH_REF, 'somav.h5'\n",
    "                                                ), 'r') as f:\n",
    "                        Vrest = np.median(f[Y][()][:, TRANSIENT:])\n",
    "                else:  # perseg_Vrest == True\n",
    "                    with h5py.File(os.path.join(OUTPUTPATH_REF, 'vmem.h5'\n",
    "                                                ), 'r') as f:\n",
    "                        Vrest = np.mean(f[Y][()][:, TRANSIENT:], axis=-1)\n",
    "        \n",
    "        if perseg_Vrest:\n",
    "            ax.plot(Vrest, '.', color=color)\n",
    "            ax.axis(ax.axis('tight'))\n",
    "        else:\n",
    "            ax.hlines(Vrest, 0, 641, color=color)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a313efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute spike-LFP and spike-dipole moment kernel approximations\n",
    "# obtained using the KernelApprox class. \n",
    "\n",
    "# outer iterator over the different ground truth datasets\n",
    "# as we need some Vrest value to linearize around\n",
    "# as well as the population firing rates\n",
    "H_YX_pred_all = dict()\n",
    "\n",
    "for pset_ref in PS_ref.iter_inner():\n",
    "    js_ref = json.dumps(pset_ref, sort_keys=True).encode()\n",
    "    md5_ref = hashlib.md5(js_ref).hexdigest()\n",
    "    OUTPUTPATH_REF = os.path.join('output', md5_ref)\n",
    "    print(OUTPUTPATH_REF, os.path.isdir(OUTPUTPATH_REF))\n",
    "\n",
    "    # kernel container\n",
    "    H_YX_pred = dict()\n",
    "    for k, pset in enumerate(PS2.iter_inner()):\n",
    "        # parameters.\n",
    "        pset['weight_scaling'] = pset_ref['weight_scaling']  # use reference value!\n",
    "        \n",
    "        weight_EE = pset['weight_EE']\n",
    "        weight_IE = pset['weight_IE']\n",
    "        weight_EI = pset['weight_EI']\n",
    "        weight_II = pset['weight_II']\n",
    "        weight_scaling = pset['weight_scaling'] \n",
    "        biophys = pset['biophys']\n",
    "        n_ext = pset['n_ext']\n",
    "        g_eff = pset['g_eff']\n",
    "        perseg_Vrest = pset['perseg_Vrest']     \n",
    "\n",
    "        # sorted json dictionary\n",
    "        js = json.dumps(pset, sort_keys=True).encode()\n",
    "        md5 = hashlib.md5(js).hexdigest()\n",
    "        \n",
    "        t_X = TRANSIENT  # presynaptic activation time\n",
    "\n",
    "        # define biophysical membrane properties\n",
    "        if biophys == 'pas':\n",
    "            custom_fun = [methods.set_pas_hay2011, methods.make_cell_uniform]\n",
    "        elif biophys == 'frozen':\n",
    "            custom_fun = [methods.set_frozen_hay2011, methods.make_cell_uniform]\n",
    "        elif biophys == 'frozen_no_Ih':\n",
    "            custom_fun = [methods.set_frozen_hay2011_no_Ih, methods.make_cell_uniform]\n",
    "        elif biophys == 'lin':\n",
    "            custom_fun = [methods.set_Ih_linearized_hay2011, methods.make_cell_uniform]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # synapse max. conductance (function, mean, st.dev., min.):\n",
    "        # weights = np.array([[weight_EE, weight_IE],\n",
    "        #                     [weight_EI, weight_II]]) * weight_scaling\n",
    "        \n",
    "        weights = np.array([\n",
    "            [weight_EE * weight_scaling**(weight_EI / weight_EE),\n",
    "             weight_IE * weight_scaling**(weight_II / weight_IE)], \n",
    "            [weight_EI * weight_scaling**(weight_EE / weight_EI),\n",
    "             weight_II * weight_scaling**(weight_IE / weight_II)]\n",
    "        ])\n",
    "        \n",
    "        # class RecExtElectrode/PointSourcePotential parameters:\n",
    "        electrodeParameters = params.electrodeParameters.copy()\n",
    "        for key in ['r', 'n', 'N', 'method']:\n",
    "            del electrodeParameters[key]\n",
    "\n",
    "        # Not using RecExtElectrode class as we anyway average potential in\n",
    "        # space for each source element. This is to replaced by\n",
    "        # a closed form volumetric method (point source & volumetric contacts\n",
    "        # should result in same mappings as volumetric source & point contacs)\n",
    "\n",
    "        # Predictor assuming planar disk source elements convolved with Gaussian\n",
    "        # along z-axis\n",
    "        gauss_cyl_potential = GaussCylinderPotential(\n",
    "            cell=None,\n",
    "            z=electrodeParameters['z'],\n",
    "            sigma=electrodeParameters['sigma'],\n",
    "            R=params.populationParameters['pop_args']['radius'],\n",
    "            sigma_z=params.populationParameters['pop_args']['scale'],\n",
    "            )\n",
    "\n",
    "        # set up recording of current dipole moments.\n",
    "        current_dipole_moment = CurrentDipoleMoment(cell=None)\n",
    "\n",
    "        # Compute average firing rate of presynaptic populations X\n",
    "        mean_nu_X = methods.compute_mean_nu_X(params, OUTPUTPATH_REF,\n",
    "                                         TRANSIENT=TRANSIENT)\n",
    "\n",
    "        # kernel container\n",
    "        H_YX_pred[md5] = dict()\n",
    "\n",
    "        for i, (X, N_X) in enumerate(zip(params.population_names,\n",
    "                                         params.population_sizes)):\n",
    "            # for j, (Y, N_Y) in enumerate(zip(params.population_names, \n",
    "            #                                  params.population_sizes)):            \n",
    "            for j, (Y, N_Y) in enumerate(zip([params.population_names[0]], \n",
    "                                             [params.population_sizes[0]])):            \n",
    "                # Extract median soma voltages from actual network simulation and\n",
    "                # assume this value corresponds to Vrest.\n",
    "                if not perseg_Vrest:\n",
    "                    with h5py.File(os.path.join(OUTPUTPATH_REF, 'somav.h5'\n",
    "                                                ), 'r') as f:\n",
    "                        Vrest = np.median(f[Y][()][:, TRANSIENT:])\n",
    "                else:  # perseg_Vrest == True\n",
    "                    with h5py.File(os.path.join(OUTPUTPATH_REF, 'vmem.h5'\n",
    "                                                ), 'r') as f:\n",
    "                        Vrest = np.mean(f[Y][()][:, TRANSIENT:], axis=-1)\n",
    "                \n",
    "                cellParameters = deepcopy(params.cellParameters[Y])\n",
    "                if biophys == 'frozen':\n",
    "                    if Y == 'E':\n",
    "                        cellParameters.update({\n",
    "                            'templatefile': [\n",
    "                                'L5bPCmodelsEH/models/L5PCbiophys3_frozen.hoc',\n",
    "                                'L5bPCmodelsEH/models/L5PCtemplate_frozen.hoc'\n",
    "                                ],\n",
    "                            'templatename': 'L5PCtemplate_frozen',\n",
    "                            'custom_fun': [\n",
    "                                methods.set_V_R,\n",
    "                                methods.make_cell_uniform\n",
    "                                ],\n",
    "                            'custom_fun_args': [dict(Vrest=Vrest)] * 2,\n",
    "                        })\n",
    "                    elif Y == 'I':\n",
    "                        cellParameters.update({\n",
    "                            'custom_fun': [\n",
    "                                methods.set_frozen_hay2011,\n",
    "                                methods.make_cell_uniform\n",
    "                                ],\n",
    "                            'custom_fun_args': [dict(Vrest=Vrest)] * 2,\n",
    "                        })\n",
    "                    else:\n",
    "                        raise Exception(f'population {Y} not recognized')\n",
    "                elif biophys == 'lin':\n",
    "                    if Y == 'E':\n",
    "                        cellParameters.update({\n",
    "                            'templatefile': [\n",
    "                                'L5bPCmodelsEH/models/L5PCbiophys3_lin.hoc',\n",
    "                                'L5bPCmodelsEH/models/L5PCtemplate_lin.hoc'\n",
    "                                ],\n",
    "                            'templatename': 'L5PCtemplate_lin',\n",
    "                            'custom_fun': [\n",
    "                                methods.set_V_R,\n",
    "                                methods.make_cell_uniform\n",
    "                                ],\n",
    "                            'custom_fun_args': [dict(Vrest=Vrest)] * 2,\n",
    "                        })\n",
    "                    elif Y == 'I':\n",
    "                        cellParameters.update({\n",
    "                            'custom_fun': [\n",
    "                                methods.set_Ih_linearized_hay2011,\n",
    "                                methods.make_cell_uniform\n",
    "                                ],\n",
    "                            'custom_fun_args': [dict(Vrest=Vrest)] * 2,\n",
    "                        })\n",
    "                    else:\n",
    "                        raise Exception(f'population {Y} not recognized')\n",
    "                elif biophys == 'pas':\n",
    "                    if Y == 'E':\n",
    "                        cellParameters.update({\n",
    "                            'templatefile': [\n",
    "                                'L5bPCmodelsEH/models/L5PCbiophys3_pas.hoc',\n",
    "                                'L5bPCmodelsEH/models/L5PCtemplate_pas.hoc'\n",
    "                                ],\n",
    "                            'templatename': 'L5PCtemplate_pas',\n",
    "                            'custom_fun': [\n",
    "                                methods.make_cell_uniform\n",
    "                                ],\n",
    "                            'custom_fun_args': [dict(Vrest=Vrest)],\n",
    "                        })\n",
    "                    elif Y == 'I':\n",
    "                        cellParameters.update({\n",
    "                            'custom_fun': [\n",
    "                                methods.set_pas_hay2011,\n",
    "                                methods.make_cell_uniform\n",
    "                                ],\n",
    "                            'custom_fun_args': [dict(Vrest=Vrest)] * 2,\n",
    "                        })\n",
    "                    else:\n",
    "                        raise Exception(f'population {Y} not recognized')\n",
    "                else:\n",
    "                    raise NotImplementedError(f'biophys={biophys} not implemented')\n",
    "\n",
    "                # population parameters\n",
    "                populationParameters = deepcopy(params.populationParameters)\n",
    "                populationParameters['rotation_args'] = deepcopy(params.rotation_args[Y])\n",
    "                populationParameters['cell_args'] = cellParameters\n",
    "\n",
    "                # some inputs must be lists\n",
    "                synapseParameters = [\n",
    "                    dict(weight=weights[ii][j],\n",
    "                         syntype='Exp2Syn',\n",
    "                         **params.synapseParameters[ii][j])\n",
    "                    for ii in range(len(params.population_names))]\n",
    "                synapsePositionArguments = [\n",
    "                    params.synapsePositionArguments[ii][j]\n",
    "                    for ii in range(len(params.population_names))]\n",
    "\n",
    "                # Create kernel approximator object\n",
    "                kernel = KernelApprox(\n",
    "                    X=params.population_names,\n",
    "                    Y=Y,\n",
    "                    N_X=np.array(params.population_sizes),\n",
    "                    N_Y=N_Y,\n",
    "                    C_YX=np.array(params.connectionProbability[i]),\n",
    "                    cellParameters=cellParameters,\n",
    "                    populationParameters=params.populationParameters['pop_args'],\n",
    "                    rotationParameters=params.rotation_args[Y],\n",
    "                    multapseFunction=params.multapseFunction,\n",
    "                    multapseParameters=[params.multapseArguments[ii][j] for ii in range(len(params.population_names))],\n",
    "                    delayFunction=params.delayFunction,\n",
    "                    delayParameters=[params.delayArguments[ii][j] for ii in range(len(params.population_names))],\n",
    "                    synapseParameters=synapseParameters,\n",
    "                    synapsePositionArguments=synapsePositionArguments,\n",
    "                    extSynapseParameters=params.extSynapseParameters,\n",
    "                    nu_ext=1000. / params.netstim_interval,\n",
    "                    n_ext=n_ext[j],\n",
    "                    nu_X=mean_nu_X,\n",
    "                )\n",
    "                \n",
    "                # make kernel predictions\n",
    "                H_YX_pred[md5]['{}:{}'.format(Y, X)] = kernel.get_kernel(\n",
    "                    probes=[gauss_cyl_potential, current_dipole_moment],\n",
    "                    Vrest=Vrest, dt=dt, X=X, t_X=t_X, tau=tau,\n",
    "                    g_eff=g_eff,\n",
    "                )\n",
    "                \n",
    "    # Save\n",
    "    H_YX_pred_all[md5_ref] = H_YX_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dc721f-5f1f-4ddf-b0c6-19921161cd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattenlist(lst):\n",
    "    return [item for sublist in lst for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbd679e-7c2c-4487-a6ad-0995e69562b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outer iterator over the different ground truth datasets\n",
    "tstop = params.networkParameters['tstop']\n",
    "dt = params.networkParameters['dt']\n",
    "\n",
    "\n",
    "# container\n",
    "df = pd.DataFrame(columns=['R2', 'STD/STD', 'weight_scaling', 'probe', 'signal', 'channel', 'perseg_Vrest'])\n",
    "    \n",
    "for hh, pset_ref in enumerate(PS_ref.iter_inner()):\n",
    "    js_ref = json.dumps(pset_ref, sort_keys=True).encode()\n",
    "    md5_ref = hashlib.md5(js_ref).hexdigest()\n",
    "    OUTPUTPATH_REF = os.path.join('output', md5_ref)\n",
    "    print(OUTPUTPATH_REF, os.path.isdir(OUTPUTPATH_REF))\n",
    "    \n",
    "    \n",
    "    # compute firing rate time series of \"real\" network\n",
    "    tstop = networkParameters['tstop']\n",
    "    nu_X, bins = methods.compute_nu_X(os.path.join(OUTPUTPATH_REF, 'spikes.h5'), population_names, \n",
    "                                           T=(0, tstop), Delta_t=dt)\n",
    "            \n",
    "    \n",
    "    # compute and show R2 and STD ratio between ground truth and prediction\n",
    "    for j, (fname, ylabel, probe, unit, vlimround) in enumerate(zip(\n",
    "            ['RecExtElectrode.h5', 'CurrentDipoleMoment.h5'],\n",
    "            [r'$V_\\mathrm{e}$', r'$\\mathbf{P}$'],\n",
    "            ['GaussCylinderPotential', 'CurrentDipoleMoment'],\n",
    "            ['mV', 'nAµm'],\n",
    "            [2**-1, 2**18])):\n",
    "        with h5py.File(os.path.join(OUTPUTPATH_REF, fname),\n",
    "                       'r') as f:\n",
    "            data_ref = f['data'][()]['E']\n",
    "        \n",
    "        # low pass filter, remove startup transient\n",
    "        data_ref_lp = ss.sosfiltfilt(sos_ellip, data_ref)[:, int(TRANSIENT // dt):]\n",
    "        data_ref = data_ref[:, int(TRANSIENT // dt):]\n",
    "\n",
    "        # Compute reconstructed signals as the sum over convolutions\n",
    "        # phi(r, t) = sum_X sum_Y (nu_X*H_YX)(r, t)\n",
    "        for k, pset in enumerate(PS2.iter_inner()):\n",
    "            pset['weight_scaling'] = pset_ref['weight_scaling']  # use reference value!\n",
    "            \n",
    "            # sorted json dictionary\n",
    "            js = json.dumps(pset, sort_keys=True).encode()\n",
    "            md5 = hashlib.md5(js).hexdigest()\n",
    "            \n",
    "            # signal container\n",
    "            data = None\n",
    "\n",
    "            for i, (X, N_X) in enumerate(zip(population_names,\n",
    "                                             population_sizes)):\n",
    "                for Y in ['E']: # population_names:\n",
    "                    if data is None:\n",
    "                        data = np.zeros((H_YX_pred_all[md5_ref][md5]['{}:{}'.format(Y, X)][probe].shape[0],\n",
    "                                         nu_X[X].size))\n",
    "                    for h, h_YX in enumerate(H_YX_pred_all[md5_ref][md5]['{}:{}'.format(Y, X)][probe]):\n",
    "                        data[h, :] = data[h, :] + np.convolve(nu_X[X], h_YX,\n",
    "                                                              'same')\n",
    "            # low-pass filter, remove startup transient\n",
    "            data_lp = ss.sosfiltfilt(sos_ellip, data)[:, int(TRANSIENT // dt):]\n",
    "            data = data[:, int(TRANSIENT // dt):]\n",
    "            \n",
    "            # number of channels\n",
    "            n_ch = data.shape[0]\n",
    "\n",
    "            # Pearson correlation coefficients\n",
    "            Pcc = np.corrcoef(data_ref, data)[n_ch:, :n_ch].diagonal()\n",
    "            Pcc_lp = np.corrcoef(data_ref_lp, data_lp)[n_ch:, :n_ch].diagonal()\n",
    "\n",
    "            # STD(y) / STD(x)\n",
    "            scaling = data.std(axis=-1) / data_ref.std(axis=-1)\n",
    "            scaling_lp = data_lp.std(axis=-1) / data_ref_lp.std(axis=-1)\n",
    "\n",
    "            for ch in range(n_ch):\n",
    "                '''\n",
    "                df = df.append([\n",
    "                        pd.DataFrame(\n",
    "                            data={'R2': Pcc[ch]**2, 'STD/STD': scaling[ch], \n",
    "                                  'weight_scaling': pset_ref['weight_scaling'], \n",
    "                                  'probe': probe,\n",
    "                                  'signal': 'raw', 'channel': (ch + 1), \n",
    "                                  'perseg_Vrest': pset['perseg_Vrest']}, \n",
    "                            index=[0]\n",
    "                        ),\n",
    "                        pd.DataFrame(\n",
    "                            data={'R2': Pcc_lp[ch]**2, 'STD/STD': scaling_lp[ch], \n",
    "                                  'weight_scaling': pset_ref['weight_scaling'], \n",
    "                                  'probe': probe,\n",
    "                                  'signal': 'LP', 'channel': (ch + 1), \n",
    "                                  'perseg_Vrest': pset['perseg_Vrest']}, \n",
    "                            index=[0]\n",
    "                        ),\n",
    "                        ],\n",
    "                    ignore_index=True)\n",
    "                '''\n",
    "                df = pd.concat([\n",
    "                    df,\n",
    "                    pd.DataFrame(\n",
    "                        data={'R2': Pcc[ch]**2, 'STD/STD': scaling[ch], \n",
    "                                'weight_scaling': pset_ref['weight_scaling'], \n",
    "                                'probe': probe,\n",
    "                                'signal': 'raw', 'channel': (ch + 1), \n",
    "                                'perseg_Vrest': pset['perseg_Vrest']}, \n",
    "                        index=[0]\n",
    "                    ),\n",
    "                    pd.DataFrame(\n",
    "                        data={'R2': Pcc_lp[ch]**2, 'STD/STD': scaling_lp[ch], \n",
    "                                'weight_scaling': pset_ref['weight_scaling'], \n",
    "                                'probe': probe,\n",
    "                                'signal': 'LP', 'channel': (ch + 1), \n",
    "                                'perseg_Vrest': pset['perseg_Vrest']}, \n",
    "                        index=[0]\n",
    "                    ),\n",
    "                ], ignore_index=True)\n",
    "\n",
    "df_agg = df.groupby(['signal', 'weight_scaling', 'probe', 'perseg_Vrest'], as_index=False\n",
    "                    ).agg({'R2': ['mean', 'median', methods.quant10, methods.quant90], \n",
    "                           'STD/STD': ['mean', 'median', methods.quant10, methods.quant90]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4666b1-cfa7-448e-9d56-1654716296cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3d9169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregated mean and standard deviations etc. of R2 and STD ratio\n",
    "df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a10a1d-c140-4003-acb2-d99f3d31ff36",
   "metadata": {},
   "outputs": [],
   "source": [
    "markersize = 8\n",
    "\n",
    "# fig = plt.figure(figsize=(figwidth, figwidth / golden_ratio))\n",
    "# gs = GridSpec(2, 3, hspace=0.3, wspace=0.25)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(figwidth / 2, figwidth / 2))\n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.25)\n",
    "'''\n",
    "axes = []\n",
    "axes.append([fig.add_subplot(gs[:, 0])])\n",
    "for i in range(2):\n",
    "    axes.append([])\n",
    "    for j in range(2):\n",
    "        axes[i + 1].append(fig.add_subplot(gs[i, j + 1]))\n",
    "'''\n",
    "    \n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    remove_axis_junk(ax)\n",
    "    annotate_subplot(ax, ncols=2, nrows=2, letter='ABCD'[i], linear_offset=0.04)\n",
    "\n",
    "                     \n",
    "for hh, pset_ref in enumerate(PS_ref.iter_inner()):\n",
    "    js_ref = json.dumps(pset_ref, sort_keys=True).encode()\n",
    "    md5_ref = hashlib.md5(js_ref).hexdigest()\n",
    "    OUTPUTPATH_REF = os.path.join('output', md5_ref)\n",
    "    print(OUTPUTPATH_REF, os.path.isdir(OUTPUTPATH_REF))\n",
    "\n",
    "    # compute and show R2 and STD ratio between ground truth and prediction\n",
    "    for j, (fname, ylabel, probe, unit, vlimround) in enumerate(zip(\n",
    "            ['RecExtElectrode.h5', 'CurrentDipoleMoment.h5'],\n",
    "            [r'$V_\\mathrm{e}$', r'$\\mathbf{P}$'],\n",
    "            ['GaussCylinderPotential', 'CurrentDipoleMoment'],\n",
    "            ['mV', 'nAµm'],\n",
    "            [2**-1, 2**18])):\n",
    "\n",
    "        for k, pset in enumerate(PS2.iter_inner()):\n",
    "            pset['weight_scaling'] = pset_ref['weight_scaling']  # use reference value!\n",
    "            \n",
    "            # sorted json dictionary\n",
    "            js = json.dumps(pset, sort_keys=True).encode()\n",
    "            md5 = hashlib.md5(js).hexdigest()\n",
    "            \n",
    "            R2 = np.array(df[(df['weight_scaling']==pset_ref['weight_scaling']) & (df['probe']==probe) & (df['signal']=='raw') & (df['perseg_Vrest']==pset['perseg_Vrest'])]['R2'])\n",
    "            scaling = np.array(df[(df['weight_scaling']==pset_ref['weight_scaling']) & (df['probe']==probe) & (df['signal']=='raw') & (df['perseg_Vrest']==pset['perseg_Vrest'])]['STD/STD'])\n",
    "                     \n",
    "            R2_lp = np.array(df[(df['weight_scaling']==pset_ref['weight_scaling']) & (df['probe']==probe) & (df['signal']=='LP') & (df['perseg_Vrest']==pset['perseg_Vrest'])]['R2'])\n",
    "            scaling_lp = np.array(df[(df['weight_scaling']==pset_ref['weight_scaling']) & (df['probe']==probe) & (df['signal']=='LP') & (df['perseg_Vrest']==pset['perseg_Vrest'])]['STD/STD'])\n",
    "            \n",
    "            n_ch = R2.size\n",
    "            \n",
    "            \n",
    "            if pset['perseg_Vrest']:\n",
    "                # alpha=1\n",
    "                marker = '*'\n",
    "            else:\n",
    "                # alpha=0.5\n",
    "                marker = 'o'\n",
    "            \n",
    "            # plot\n",
    "            w = pset_ref['weight_scaling']\n",
    "            # if w == 1.:\n",
    "            #     color = 'k'\n",
    "            # else:\n",
    "            color = f'C{hh}'\n",
    "            if probe == 'CurrentDipoleMoment':\n",
    "                ax = axes[1, 1]\n",
    "                \n",
    "                ax.plot(R2[2]**2, scaling[2], marker=marker, mec=color, mfc=color, ms=markersize, \n",
    "                        label=f'$J={w}$; raw', clip_on=False)\n",
    "                ax.plot(R2_lp[2]**2, scaling_lp[2], marker=marker, mec=color, mfc='w', ms=markersize, \n",
    "                        label=f'$J={w}$; LP', clip_on=False)\n",
    "                # ax.set_ylabel(r'$r_\\mathrm{STD}$')\n",
    "                ax.set_xlabel(r'$R^2$ (-)')\n",
    "            else:\n",
    "                ax = axes[0, 0]\n",
    "\n",
    "                ax.plot(R2**2, np.arange(n_ch) + 1, f'-{marker}', color=color, ms=markersize, \n",
    "                        label=f'$J={w}$; raw', clip_on=False)\n",
    "                ax.plot(R2_lp**2, np.arange(n_ch) + 1, f'-{marker}', color=color, mfc='w', ms=markersize, \n",
    "                        label=f'$J={w}$; LP', clip_on=False)\n",
    "                ax.set_xlabel(r'$R^2$ (-)')\n",
    "                # ax.set_xlim(xmax=1)\n",
    "\n",
    "                ax = axes[0, 1]\n",
    "                ax.plot(scaling, np.arange(n_ch) + 1, f'-{marker}', color=color, ms=markersize, \n",
    "                        clip_on=False)\n",
    "                ax.plot(scaling_lp, np.arange(n_ch) + 1, f'-{marker}', color=color, mfc='w', ms=markersize, \n",
    "                        clip_on=False)\n",
    "                ax.set_xlabel(r'$r_\\mathrm{STD}$')\n",
    "\n",
    "                for ax in axes[0, :]:\n",
    "                    ax.set_yticks(np.arange(n_ch) + 1)\n",
    "                    ax.set_yticklabels(['ch.{}'.format(i + 1) for i in np.arange(n_ch)])\n",
    "                plt.setp(axes[0, 1].get_yticklabels(), visible=False)\n",
    "\n",
    "                axes[0, 1].vlines(1, 1, n_ch, ls=':')\n",
    "                \n",
    "ax = axes[1, 0]\n",
    "weight_scaling = list(PS0['weight_scaling'])\n",
    "probe = 'GaussCylinderPotential'\n",
    "for i, weight in enumerate(weight_scaling):\n",
    "    for j, signal in enumerate(['raw', 'LP']):        \n",
    "        for perseg_Vrest in [False, True]:\n",
    "            if perseg_Vrest:\n",
    "                marker = '*'\n",
    "            else:\n",
    "                marker = 'o'\n",
    "            \n",
    "            d = df_agg[(df_agg['weight_scaling'] == weight) & \n",
    "                       (df_agg['signal'] == signal) & \n",
    "                       (df_agg['probe'] == probe) & \n",
    "                       (df_agg['perseg_Vrest'] == perseg_Vrest)]\n",
    "            color = f'C{i}'  #if weight != 1. else 'k'\n",
    "            ax.errorbar(x=d['R2']['median'], \n",
    "                        y=d['STD/STD']['median'],\n",
    "                        xerr=np.c_[d['R2']['median'] - d['R2']['quant10'], \n",
    "                                   d['R2']['quant90'] - d['R2']['median']].T,\n",
    "                        yerr=np.c_[d['STD/STD']['median'] - d['STD/STD']['quant10'], \n",
    "                                   d['STD/STD']['quant90'] - d['STD/STD']['median']].T,\n",
    "                        fmt=marker, \n",
    "                        ms=markersize,\n",
    "                        ecolor=color,\n",
    "                        mec=color,\n",
    "                        mfc='w' if signal == 'LP' else color,\n",
    "                        label=weight_scaling if j == 0 else '_nolegend_')\n",
    "ax.set_ylabel(r'$r_\\mathrm{STD}$')\n",
    "ax.set_xlabel('$R^2$')\n",
    "\n",
    "\n",
    "for ax in axes[0, :]:\n",
    "    ax.invert_yaxis()\n",
    "# for ax in [axes[1, 1]]:\n",
    "#    ax.legend(loc='best')\n",
    "    # ax.legend(loc='upper right', bbox_to_anchor=(1, 1))\n",
    "\n",
    "fig.savefig('figures/figureS3.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3f0ee6-9095-43b0-a141-85aeebfe5d02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('kernellfpy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "df590858b6b018e075a5c40b87c2081f6a2b114d97955d657b3e3f6005ad00da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
