{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21826193-1b94-4c45-91d2-280363f9d3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88046ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from parameters import ParameterSpace, ParameterRange, ParameterSet\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib import colors\n",
    "import h5py\n",
    "import scipy.signal as ss\n",
    "from example_network_parameters import (networkParameters, population_names,\n",
    "                                        population_sizes)\n",
    "from lfpykernels import KernelApprox, GaussCylinderPotential\n",
    "import example_network_methods as methods\n",
    "import example_network_parameters as params\n",
    "import scipy.stats as st\n",
    "from copy import deepcopy\n",
    "from plotting import draw_lineplot, annotate_subplot\n",
    "import plotting\n",
    "from lfpykit import CurrentDipoleMoment, LaminarCurrentSourceDensity\n",
    "import json\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb0cbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update(plotting.rcParams)\n",
    "golden_ratio = plotting.golden_ratio\n",
    "figwidth = plotting.figwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec943af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PS0 = ParameterSpace('PS0.txt')\n",
    "PS1 = ParameterSpace('PS1.txt')\n",
    "PS2 = ParameterSpace('PS2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a285451",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron.load_mechanisms('mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c69b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSIENT = 2000\n",
    "dt = networkParameters['dt']\n",
    "tau = 100  # max time lag relative to spike for kernel predictions\n",
    "tau_trunc = 50 # max time lag for shown in plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59af339f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.mlab.psd/csd settings\n",
    "Fs = 1000 / dt\n",
    "NFFT = 1024\n",
    "noverlap = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35ca78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# low-pass filter settings\n",
    "N = 2  # filter order\n",
    "rp = 0.1  # ripple in passband (dB)\n",
    "rs = 40.  # minimum attenuation required in the stop band (dB)\n",
    "fc = 100.  # critical frequency (Hz)\n",
    "\n",
    "# filter coefficients on 'sos' format\n",
    "sos_ellip = ss.ellip(N=N, rp=rp, rs=rs, Wn=fc, btype='lp', fs=Fs, output='sos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55343941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not investigate models with biophys='lin'\n",
    "PS2['biophys'] = ParameterRange(['frozen'])\n",
    "PS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6543b73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define iterable parameter space for nu_X&nu_ext (relative scaling) and V_rest (offset)\n",
    "PS3 = ParameterSpace(\n",
    "    dict(\n",
    "        nu_X_scaling=ParameterRange(np.linspace(0., 2., 21)),\n",
    "        V_rest_offset=ParameterRange(np.linspace(-10., 10., 21)),\n",
    "    )\n",
    ")\n",
    "PS3, PS3.num_conditions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f25464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out which real LFP to compare with\n",
    "for pset in PS1.iter_inner():\n",
    "    weight_EE = pset['weight_EE']\n",
    "    weight_IE = pset['weight_IE']\n",
    "    weight_EI = pset['weight_EI']\n",
    "    weight_II = pset['weight_II']\n",
    "    weight_scaling = pset['weight_scaling']\n",
    "    pset_0 = ParameterSet(dict(weight_EE=weight_EE,\n",
    "                               weight_IE=weight_IE,\n",
    "                               weight_EI=weight_EI,\n",
    "                               weight_II=weight_II,\n",
    "                               weight_scaling=weight_scaling,\n",
    "                               n_ext=PS0['n_ext'].value))\n",
    "    js_0 = json.dumps(pset_0, sort_keys=True).encode()\n",
    "    md5_0 = hashlib.md5(js_0).hexdigest()\n",
    "    OUTPUTPATH_REAL = os.path.join('output', md5_0)\n",
    "\n",
    "    break\n",
    "print(f'comparing with ground truth dataset: {OUTPUTPATH_REAL}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e325b718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average firing rate of presynaptic populations X\n",
    "mean_nu_X = methods.compute_mean_nu_X(params, OUTPUTPATH_REAL,\n",
    "                                 TRANSIENT=TRANSIENT)\n",
    "mean_nu_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61516e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract median soma voltages from actual network simulation and\n",
    "# assume this value corresponds to Vrest.\n",
    "Vrest_Y = {}\n",
    "with h5py.File(os.path.join(OUTPUTPATH_REAL, 'somav.h5'\n",
    "                            ), 'r') as f:\n",
    "    for Y in params.population_names:\n",
    "        Vrest_Y[Y] = np.median(f[Y][()][:, TRANSIENT:])\n",
    "Vrest_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a136ce22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute firing rate time series of \"real\" network (as spikes per time bin of width dt)\n",
    "nu_X = dict()\n",
    "tstop = networkParameters['tstop']\n",
    "bins = (np.arange(0, tstop / dt + 2)\n",
    "        * dt - dt / 2)\n",
    "with h5py.File(os.path.join(OUTPUTPATH_REAL, 'spikes.h5'), 'r') as f:\n",
    "    for i, X in enumerate(params.population_names):\n",
    "        hist = np.histogram(np.concatenate(f[X]['times']), bins=bins)[0]\n",
    "        nu_X[X] = hist.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24cceee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214e91b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth dataset for comparison\n",
    "probe = 'CurrentDipoleMoment'\n",
    "with h5py.File(os.path.join(OUTPUTPATH_REAL, f'{probe}.h5'),\n",
    "               'r') as f:\n",
    "    data_gt = f['data']['imem'][-1, ]\n",
    "\n",
    "# low pass filter\n",
    "data_gt_lp = ss.sosfiltfilt(sos_ellip, data_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b9158d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precompute standard deviations\n",
    "data_gt_std = data_gt[int(TRANSIENT // dt):].std()\n",
    "data_gt_lp_std = data_gt_lp[int(TRANSIENT // dt):].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2c3bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spike-dipole moment kernel approximations\n",
    "# obtained using the KernelApprox class\n",
    "\n",
    "# kernel container\n",
    "H_YX_pred = dict()\n",
    "for k, pset in enumerate(PS2.iter_inner()):\n",
    "    for pset_inner in PS3.iter_inner():\n",
    "        # sorted json dictionary\n",
    "        pset = {**pset, **pset_inner}  # merge dicts\n",
    "        js = json.dumps(pset, sort_keys=True).encode()\n",
    "        md5 = hashlib.md5(js).hexdigest()\n",
    "\n",
    "        # parameters\n",
    "        weight_EE = pset['weight_EE']\n",
    "        weight_IE = pset['weight_IE']\n",
    "        weight_EI = pset['weight_EI']\n",
    "        weight_II = pset['weight_II']\n",
    "        weight_scaling = pset['weight_scaling']\n",
    "        biophys = pset['biophys']\n",
    "        n_ext = pset['n_ext']\n",
    "        g_eff = pset['g_eff']\n",
    "\n",
    "        t_X = TRANSIENT  # presynaptic activation time\n",
    "\n",
    "        # define biophysical membrane properties\n",
    "        if biophys == 'pas':\n",
    "            custom_fun = [methods.set_pas_hay2011, methods.make_cell_uniform]\n",
    "        elif biophys == 'frozen':\n",
    "            custom_fun = [methods.set_frozen_hay2011, methods.make_cell_uniform]\n",
    "        elif biophys == 'frozen_no_Ih':\n",
    "            custom_fun = [methods.set_frozen_hay2011_no_Ih, methods.make_cell_uniform]\n",
    "        elif biophys == 'lin':\n",
    "            custom_fun = [methods.set_Ih_linearized_hay2011, methods.make_cell_uniform]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # synapse max. conductance (function, mean, st.dev., min.):\n",
    "        weights = np.array([[weight_EE, weight_IE],\n",
    "                            [weight_EI, weight_II]]) * weight_scaling\n",
    "\n",
    "\n",
    "        # set up recording of current dipole moments.\n",
    "        current_dipole_moment = CurrentDipoleMoment(cell=None)\n",
    "\n",
    "        # create rescaled nu_X parameter for KernelApprox class\n",
    "        nu_X_scaled = {}\n",
    "        for X in params.population_names:\n",
    "            nu_X_scaled.update({X:mean_nu_X[X] * pset['nu_X_scaling']})\n",
    "\n",
    "\n",
    "        # kernel container\n",
    "        H_YX_pred[md5] = dict()\n",
    "\n",
    "        for i, (X, N_X) in enumerate(zip(params.population_names,\n",
    "                                         params.population_sizes)):\n",
    "            for j, (Y, N_Y, morphology) in enumerate(zip(params.population_names,\n",
    "                                                         params.population_sizes,\n",
    "                                                         params.morphologies)):\n",
    "                # update cellParameters dict\n",
    "                cellParameters = deepcopy(params.cellParameters)\n",
    "                cellParameters.update(dict(\n",
    "                    morphology=morphology,\n",
    "                    custom_fun=custom_fun,\n",
    "                    custom_fun_args=[dict(Vrest=Vrest_Y[Y] + pset['V_rest_offset']), \n",
    "                                     dict(Vrest=Vrest_Y[Y] + pset['V_rest_offset'])],\n",
    "                ))\n",
    "\n",
    "                # some inputs must be lists\n",
    "                synapseParameters = [\n",
    "                    dict(weight=weights[ii][j],\n",
    "                         syntype='Exp2Syn',\n",
    "                         **params.synapseParameters[ii][j])\n",
    "                    for ii in range(len(params.population_names))]\n",
    "                synapsePositionArguments = [\n",
    "                    params.synapsePositionArguments[ii][j]\n",
    "                    for ii in range(len(params.population_names))]\n",
    "\n",
    "                \n",
    "                # Create kernel approximator object\n",
    "                kernel = KernelApprox(\n",
    "                    X=params.population_names,\n",
    "                    Y=Y,\n",
    "                    N_X=np.array(params.population_sizes),\n",
    "                    N_Y=N_Y,\n",
    "                    C_YX=np.array(params.connectionProbability[i]),\n",
    "                    cellParameters=cellParameters,\n",
    "                    populationParameters=params.populationParameters['pop_args'],\n",
    "                    multapseFunction=params.multapseFunction,\n",
    "                    multapseParameters=[params.multapseArguments[ii][j] for ii in range(len(params.population_names))],\n",
    "                    delayFunction=params.delayFunction,\n",
    "                    delayParameters=[params.delayArguments[ii][j] for ii in range(len(params.population_names))],\n",
    "                    synapseParameters=synapseParameters,\n",
    "                    synapsePositionArguments=synapsePositionArguments,\n",
    "                    extSynapseParameters=params.extSynapseParameters,\n",
    "                    nu_ext=1000. / params.netstim_interval * pset['nu_X_scaling'],\n",
    "                    n_ext=n_ext[j],\n",
    "                    nu_X=nu_X_scaled,\n",
    "                )\n",
    "\n",
    "                # make kernel predictions\n",
    "                H_YX_pred[md5]['{}:{}'.format(Y, X)] = kernel.get_kernel(\n",
    "                    probes=[current_dipole_moment],\n",
    "                    Vrest=Vrest_Y[Y] + pset['V_rest_offset'], dt=dt, X=X, t_X=t_X, tau=tau,\n",
    "                    g_eff=g_eff,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fe9b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute R^2 and r_STD metrics between ground truth and approximated signals equal to sum_X sum_Y (nu_X * H_YX)\n",
    "\n",
    "# container\n",
    "df = pd.DataFrame(columns=['md5', 'R2', 'r_STD', 'signal'])\n",
    "\n",
    "for k, pset in enumerate(PS2.iter_inner()):\n",
    "    for pset_inner in PS3.iter_inner():\n",
    "        # sorted json dictionary\n",
    "        pset = {**pset, **pset_inner}  # merge dicts\n",
    "        js = json.dumps(pset, sort_keys=True).encode()\n",
    "        md5 = hashlib.md5(js).hexdigest()\n",
    "        \n",
    "        # approximate signals using computed kernels\n",
    "        data = None\n",
    "        for X in population_names:\n",
    "            for Y in population_names:\n",
    "                if data is None:\n",
    "                    data = np.zeros(nu_X[X].size)\n",
    "                # for h, h_YX in enumerate(H_YX_pred[md5]['{}:{}'.format(Y, X)][probe]):\n",
    "                data = data + np.convolve(nu_X[X], H_YX_pred[md5]['{}:{}'.format(Y, X)][probe][-1, :], 'same')\n",
    "        # low pass filter\n",
    "        data_lp = ss.sosfiltfilt(sos_ellip, data)\n",
    "        \n",
    "        # Pearson correlation coefficients\n",
    "        Pcc = np.corrcoef(data_gt[int(TRANSIENT // dt):], \n",
    "                          data[int(TRANSIENT // dt):])[1:, :1].diagonal()\n",
    "        Pcc_lp = np.corrcoef(data_gt_lp[int(TRANSIENT // dt):],\n",
    "                             data_lp[int(TRANSIENT // dt):])[1:, :1].diagonal()\n",
    "\n",
    "        scaling = data[int(TRANSIENT  // dt):].std() / data_gt_std\n",
    "        scaling_lp = data_lp[int(TRANSIENT // dt):].std() / data_gt_lp_std\n",
    "\n",
    "        df = pd.concat([\n",
    "                df, \n",
    "                pd.DataFrame(\n",
    "                    data={'md5': md5, 'R2': Pcc**2, 'r_STD': scaling, 'signal': 'raw'}, \n",
    "                    index=[0]\n",
    "                ),\n",
    "                pd.DataFrame(\n",
    "                    data={'md5': md5, 'R2': Pcc_lp**2, 'r_STD': scaling_lp, 'signal': 'LP'}, \n",
    "                    index=[0]\n",
    "                ),\n",
    "                ],\n",
    "            ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc9ff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot R2 and r_STD metrics as function of nu_X_scaling and V_rest_offset\n",
    "fig, axes = plt.subplots(PS2.num_conditions() * 2, 2, figsize=(figwidth / 2, figwidth / 2), sharex=True, sharey=True)\n",
    "fig.subplots_adjust(wspace=0.2)\n",
    "\n",
    "for i, ax in enumerate(axes[:, 0]):\n",
    "    annotate_subplot(ax, ncols=2, nrows=2, letter='ABCDEFGHIJ'[i], linear_offset=0.04)\n",
    "\n",
    "for pset in PS2.iter_inner():\n",
    "    \n",
    "    # containers for plotting\n",
    "    dim, keys = PS3.parameter_space_dimension_labels()\n",
    "    for k, metric in enumerate(['R2', 'r_STD']):\n",
    "        if metric == 'R2':\n",
    "            cmap = 'viridis'\n",
    "            norm = colors.Normalize(vmin=df[metric].min(), vmax=df[metric].max())\n",
    "        elif metric == 'r_STD':\n",
    "            cmap = 'RdBu_r'\n",
    "            def _forward(x): return np.log2(x)\n",
    "            def _inverse(x): return 2**x\n",
    "            norm = colors.FuncNorm((_forward, _inverse), vmin=0.25, vmax=4)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        metric_nice = '$R^2$' if metric == 'R2' else '$r_\\mathrm{STD}$'\n",
    "        \n",
    "        h = 0\n",
    "        for signal in ['raw', 'LP']:\n",
    "            imdata = np.zeros(dim)\n",
    "            for i, value_i in enumerate(PS3[keys[0]]):\n",
    "                for j, value_j in enumerate(PS3[keys[1]]):\n",
    "                    pset = {**pset, **{keys[0]: value_i, keys[1]:value_j}}  # merge dicts\n",
    "                    js = json.dumps(pset, sort_keys=True).encode()\n",
    "                    md5 = hashlib.md5(js).hexdigest()\n",
    "                    imdata[i, j] = df[(df['md5'].values==md5) & (df['signal'].values==signal)][metric].values\n",
    "            \n",
    "            \n",
    "            ax = axes[k, h]\n",
    "            \n",
    "            im = ax.pcolormesh(list(PS3[keys[1]]), list(PS3[keys[0]]), imdata, shading='auto', norm=norm, cmap=cmap)\n",
    "            # add a single contour line\n",
    "            if metric == 'R2':\n",
    "                levels = [0.95, 0.98, 0.99]  # explained variance\n",
    "            else: \n",
    "                levels = [0.25, 0.5, 1, 2, 4]  # \n",
    "            CS = ax.contour(list(PS3[keys[1]]), list(PS3[keys[0]]), imdata, levels=levels, colors=['k'])\n",
    "            ax.clabel(CS, CS.levels, inline=True, fontsize=10)\n",
    "            \n",
    "            biophys = pset['biophys']\n",
    "            ax.set_title(f'{signal}')\n",
    "            cbar = plt.colorbar(im, ax=ax)\n",
    "            cbar.set_label(metric_nice)\n",
    "            if h == 0:\n",
    "                ax.set_ylabel(r'$\\overline{V}_\\mathrm{m}^\\diamond - \\overline{V}_\\mathrm{m}$ (mV)')\n",
    "            if k == 1:\n",
    "                cbar.set_ticks(levels)\n",
    "                cbar.set_ticklabels(levels)\n",
    "                cbar.set_label(metric_nice, labelpad=-10)\n",
    "                ax.set_xlabel(r'$\\langle \\nu_X^\\diamond \\rangle / \\langle \\nu_X \\rangle$ (-)')\n",
    "            h += 1\n",
    "\n",
    "fig.savefig(os.path.join('figures', 'figure08.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b29fe9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('kernellfpy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "df590858b6b018e075a5c40b87c2081f6a2b114d97955d657b3e3f6005ad00da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
