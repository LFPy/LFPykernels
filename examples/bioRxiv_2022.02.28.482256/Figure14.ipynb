{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0c883b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928c1790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from parameters import ParameterSpace, ParameterSet, ParameterRange\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import h5py\n",
    "import scipy.signal as ss\n",
    "from hay2011_network_parameters import (networkParameters, population_names,\n",
    "                                        population_sizes)\n",
    "from plotting import remove_axis_junk\n",
    "from lfpykernels import KernelApprox, GaussCylinderPotential\n",
    "import example_network_methods as methods\n",
    "import hay2011_network_parameters as params\n",
    "import scipy.stats as st\n",
    "from copy import deepcopy\n",
    "from plotting import draw_lineplot, annotate_subplot\n",
    "import plotting\n",
    "from lfpykit import CurrentDipoleMoment, LaminarCurrentSourceDensity\n",
    "import json\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df285b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update(plotting.rcParams)\n",
    "golden_ratio = plotting.golden_ratio\n",
    "figwidth = plotting.figwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa543452",
   "metadata": {},
   "outputs": [],
   "source": [
    "PS0 = ParameterSpace('hay2011_PS0.txt')\n",
    "PS1 = ParameterSpace('hay2011_PS1.txt')\n",
    "PS2 = ParameterSpace('hay2011_PS2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4753bb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore quasi-linearization\n",
    "PS2['biophys'] = ParameterRange(['frozen'])\n",
    "PS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8434f61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron.load_mechanisms('mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54ccf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSIENT = 2000\n",
    "dt = networkParameters['dt']\n",
    "tau = 100  # time lag relative to spike for kernel predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efbe45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ss.welch/plt.mlab.psd/csd settings\n",
    "Fs = 1000 / dt\n",
    "NFFT = 1024 * 2\n",
    "noverlap = 768 * 2\n",
    "detrend = False\n",
    "freqs_cutoff = 1000.  # (Hz) ignore freqs above this in spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d4674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# low-pass filter settings\n",
    "N = 2  # filter order\n",
    "rp = 0.1  # ripple in passband (dB)\n",
    "rs = 40.  # minimum attenuation required in the stop band (dB)\n",
    "fc = 100.  # critical frequency (Hz)\n",
    "\n",
    "# filter coefficients on 'sos' format\n",
    "sos_ellip = ss.ellip(N=N, rp=rp, rs=rs, Wn=fc, btype='lp', fs=Fs, output='sos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2313e5-1ac6-4ffe-8455-f0c8316e4f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# E and I colors\n",
    "colors = ['tab:blue', 'tab:red']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09069ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a ground truth parameterset list where 'weight_scaling' is varied\n",
    "# which is used to extract spike rates and ground truth signals\n",
    "for pset in PS1.iter_inner():\n",
    "    break\n",
    "pset['weight_scaling'] = PS0['weight_scaling']\n",
    "for key in ['biophys', 'i_syn', 'g_eff', 'perseg_Vrest']:\n",
    "    pset.pop(key)\n",
    "PS_ref = ParameterSpace(pset)\n",
    "\n",
    "for pset_ref in PS_ref.iter_inner():\n",
    "    js_ref = json.dumps(pset_ref, sort_keys=True).encode()\n",
    "    md5_ref = hashlib.md5(js_ref).hexdigest()\n",
    "    OUTPUTPATH_REF = os.path.join('output', md5_ref)\n",
    "    print(OUTPUTPATH_REF, os.path.isdir(OUTPUTPATH_REF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d676fc1c-298d-463a-a7e4-91f6b840fddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flag; if True, use the median membrane potential per compartment for kernel predictions \n",
    "perseg_Vrest = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a313efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute spike-LFP and spike-dipole moment kernel approximations\n",
    "# obtained using the KernelApprox class. \n",
    "\n",
    "# outer iterator over the different ground truth datasets\n",
    "# as we need some Vrest value to linearize around\n",
    "# as well as the population firing rates\n",
    "H_YX_pred_all = dict()\n",
    "\n",
    "for pset_ref in PS_ref.iter_inner():\n",
    "    js_ref = json.dumps(pset_ref, sort_keys=True).encode()\n",
    "    md5_ref = hashlib.md5(js_ref).hexdigest()\n",
    "    OUTPUTPATH_REF = os.path.join('output', md5_ref)\n",
    "    print(OUTPUTPATH_REF, os.path.isdir(OUTPUTPATH_REF))\n",
    "\n",
    "    # kernel container\n",
    "    H_YX_pred = dict()\n",
    "    for k, pset in enumerate(PS2.iter_inner()):\n",
    "        # parameters.\n",
    "        pset['weight_scaling'] = pset_ref['weight_scaling']  # use reference value!\n",
    "        \n",
    "        weight_EE = pset['weight_EE']\n",
    "        weight_IE = pset['weight_IE']\n",
    "        weight_EI = pset['weight_EI']\n",
    "        weight_II = pset['weight_II']\n",
    "        weight_scaling = pset['weight_scaling'] \n",
    "        biophys = pset['biophys']\n",
    "        n_ext = pset['n_ext']\n",
    "        g_eff = pset['g_eff']\n",
    "\n",
    "        # sorted json dictionary\n",
    "        js = json.dumps(pset, sort_keys=True).encode()\n",
    "        md5 = hashlib.md5(js).hexdigest()\n",
    "        \n",
    "        t_X = TRANSIENT  # presynaptic activation time\n",
    "\n",
    "        # define biophysical membrane properties\n",
    "        if biophys == 'pas':\n",
    "            custom_fun = [methods.set_pas_hay2011, methods.make_cell_uniform]\n",
    "        elif biophys == 'frozen':\n",
    "            custom_fun = [methods.set_frozen_hay2011, methods.make_cell_uniform]\n",
    "        elif biophys == 'frozen_no_Ih':\n",
    "            custom_fun = [methods.set_frozen_hay2011_no_Ih, methods.make_cell_uniform]\n",
    "        elif biophys == 'lin':\n",
    "            custom_fun = [methods.set_Ih_linearized_hay2011, methods.make_cell_uniform]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # synapse max. conductance (function, mean, st.dev., min.):\n",
    "        # weights = np.array([[weight_EE, weight_IE],\n",
    "        #                     [weight_EI, weight_II]]) * weight_scaling\n",
    "        \n",
    "        weights = np.array([\n",
    "            [weight_EE * weight_scaling**(weight_EI / weight_EE),\n",
    "             weight_IE * weight_scaling**(weight_II / weight_IE)], \n",
    "            [weight_EI * weight_scaling**(weight_EE / weight_EI),\n",
    "             weight_II * weight_scaling**(weight_IE / weight_II)]\n",
    "        ])\n",
    "        \n",
    "        # class RecExtElectrode/PointSourcePotential parameters:\n",
    "        electrodeParameters = params.electrodeParameters.copy()\n",
    "        for key in ['r', 'n', 'N', 'method']:\n",
    "            del electrodeParameters[key]\n",
    "\n",
    "        # Not using RecExtElectrode class as we anyway average potential in\n",
    "        # space for each source element. This is to replaced by\n",
    "        # a closed form volumetric method (point source & volumetric contacts\n",
    "        # should result in same mappings as volumetric source & point contacs)\n",
    "\n",
    "        # Predictor assuming planar disk source elements convolved with Gaussian\n",
    "        # along z-axis\n",
    "        gauss_cyl_potential = GaussCylinderPotential(\n",
    "            cell=None,\n",
    "            z=electrodeParameters['z'],\n",
    "            sigma=electrodeParameters['sigma'],\n",
    "            R=params.populationParameters['pop_args']['radius'],\n",
    "            sigma_z=params.populationParameters['pop_args']['scale'],\n",
    "            )\n",
    "\n",
    "        # set up recording of current dipole moments.\n",
    "        current_dipole_moment = CurrentDipoleMoment(cell=None)\n",
    "\n",
    "        # Compute average firing rate of presynaptic populations X\n",
    "        mean_nu_X = methods.compute_mean_nu_X(params, OUTPUTPATH_REF,\n",
    "                                         TRANSIENT=TRANSIENT)\n",
    "\n",
    "        # kernel container\n",
    "        H_YX_pred[md5] = dict()\n",
    "\n",
    "        for i, (X, N_X) in enumerate(zip(params.population_names,\n",
    "                                         params.population_sizes)):\n",
    "            # for j, (Y, N_Y) in enumerate(zip(params.population_names, \n",
    "            #                                  params.population_sizes)):            \n",
    "            for j, (Y, N_Y) in enumerate(zip([params.population_names[0]], \n",
    "                                             [params.population_sizes[0]])):            \n",
    "                # Extract median soma voltages from actual network simulation and\n",
    "                # assume this value corresponds to Vrest.\n",
    "                if not perseg_Vrest:\n",
    "                    with h5py.File(os.path.join(OUTPUTPATH_REF, 'somav.h5'\n",
    "                                                ), 'r') as f:\n",
    "                        Vrest = np.median(f[Y][()][:, TRANSIENT:])\n",
    "                else:  # perseg_Vrest == True\n",
    "                    with h5py.File(os.path.join(OUTPUTPATH_REF, 'vmem.h5'\n",
    "                                                ), 'r') as f:\n",
    "                        Vrest = np.mean(f[Y][()][:, TRANSIENT:], axis=-1)\n",
    "                \n",
    "                cellParameters = deepcopy(params.cellParameters[Y])\n",
    "                if biophys == 'frozen':\n",
    "                    if Y == 'E':\n",
    "                        cellParameters.update({\n",
    "                            'templatefile': [\n",
    "                                'L5bPCmodelsEH/models/L5PCbiophys3_frozen.hoc',\n",
    "                                'L5bPCmodelsEH/models/L5PCtemplate_frozen.hoc'\n",
    "                                ],\n",
    "                            'templatename': 'L5PCtemplate_frozen',\n",
    "                            'custom_fun': [\n",
    "                                methods.set_V_R,\n",
    "                                methods.make_cell_uniform\n",
    "                                ],\n",
    "                            'custom_fun_args': [dict(Vrest=Vrest)] * 2,\n",
    "                        })\n",
    "                    elif Y == 'I':\n",
    "                        cellParameters.update({\n",
    "                            'custom_fun': [\n",
    "                                methods.set_frozen_hay2011,\n",
    "                                methods.make_cell_uniform\n",
    "                                ],\n",
    "                            'custom_fun_args': [dict(Vrest=Vrest)] * 2,\n",
    "                        })\n",
    "                    else:\n",
    "                        raise Exception(f'population {Y} not recognized')\n",
    "                elif biophys == 'lin':\n",
    "                    if Y == 'E':\n",
    "                        cellParameters.update({\n",
    "                            'templatefile': [\n",
    "                                'L5bPCmodelsEH/models/L5PCbiophys3_lin.hoc',\n",
    "                                'L5bPCmodelsEH/models/L5PCtemplate_lin.hoc'\n",
    "                                ],\n",
    "                            'templatename': 'L5PCtemplate_lin',\n",
    "                            'custom_fun': [\n",
    "                                methods.set_V_R,\n",
    "                                methods.make_cell_uniform\n",
    "                                ],\n",
    "                            'custom_fun_args': [dict(Vrest=Vrest)] * 2,\n",
    "                        })\n",
    "                    elif Y == 'I':\n",
    "                        cellParameters.update({\n",
    "                            'custom_fun': [\n",
    "                                methods.set_Ih_linearized_hay2011,\n",
    "                                methods.make_cell_uniform\n",
    "                                ],\n",
    "                            'custom_fun_args': [dict(Vrest=Vrest)] * 2,\n",
    "                        })\n",
    "                    else:\n",
    "                        raise Exception(f'population {Y} not recognized')\n",
    "                elif biophys == 'pas':\n",
    "                    if Y == 'E':\n",
    "                        cellParameters.update({\n",
    "                            'templatefile': [\n",
    "                                'L5bPCmodelsEH/models/L5PCbiophys3_pas.hoc',\n",
    "                                'L5bPCmodelsEH/models/L5PCtemplate_pas.hoc'\n",
    "                                ],\n",
    "                            'templatename': 'L5PCtemplate_pas',\n",
    "                            'custom_fun': [\n",
    "                                methods.make_cell_uniform\n",
    "                                ],\n",
    "                            'custom_fun_args': [dict(Vrest=Vrest)],\n",
    "                        })\n",
    "                    elif Y == 'I':\n",
    "                        cellParameters.update({\n",
    "                            'custom_fun': [\n",
    "                                methods.set_pas_hay2011,\n",
    "                                methods.make_cell_uniform\n",
    "                                ],\n",
    "                            'custom_fun_args': [dict(Vrest=Vrest)] * 2,\n",
    "                        })\n",
    "                    else:\n",
    "                        raise Exception(f'population {Y} not recognized')\n",
    "                else:\n",
    "                    raise NotImplementedError(f'biophys={biophys} not implemented')\n",
    "\n",
    "                # population parameters\n",
    "                populationParameters = deepcopy(params.populationParameters)\n",
    "                populationParameters['rotation_args'] = deepcopy(params.rotation_args[Y])\n",
    "                populationParameters['cell_args'] = cellParameters\n",
    "\n",
    "                # some inputs must be lists\n",
    "                synapseParameters = [\n",
    "                    dict(weight=weights[ii][j],\n",
    "                         syntype='Exp2Syn',\n",
    "                         **params.synapseParameters[ii][j])\n",
    "                    for ii in range(len(params.population_names))]\n",
    "                synapsePositionArguments = [\n",
    "                    params.synapsePositionArguments[ii][j]\n",
    "                    for ii in range(len(params.population_names))]\n",
    "\n",
    "                # Create kernel approximator object\n",
    "                kernel = KernelApprox(\n",
    "                    X=params.population_names,\n",
    "                    Y=Y,\n",
    "                    N_X=np.array(params.population_sizes),\n",
    "                    N_Y=N_Y,\n",
    "                    C_YX=np.array(params.connectionProbability[i]),\n",
    "                    cellParameters=cellParameters,\n",
    "                    populationParameters=params.populationParameters['pop_args'],\n",
    "                    rotationParameters=params.rotation_args[Y],\n",
    "                    multapseFunction=params.multapseFunction,\n",
    "                    multapseParameters=[params.multapseArguments[ii][j] for ii in range(len(params.population_names))],\n",
    "                    delayFunction=params.delayFunction,\n",
    "                    delayParameters=[params.delayArguments[ii][j] for ii in range(len(params.population_names))],\n",
    "                    synapseParameters=synapseParameters,\n",
    "                    synapsePositionArguments=synapsePositionArguments,\n",
    "                    extSynapseParameters=params.extSynapseParameters,\n",
    "                    nu_ext=1000. / params.netstim_interval,\n",
    "                    n_ext=n_ext[j],\n",
    "                    nu_X=mean_nu_X,\n",
    "                )\n",
    "                \n",
    "                # make kernel predictions\n",
    "                H_YX_pred[md5]['{}:{}'.format(Y, X)] = kernel.get_kernel(\n",
    "                    probes=[gauss_cyl_potential, current_dipole_moment],\n",
    "                    Vrest=Vrest, dt=dt, X=X, t_X=t_X, tau=tau,\n",
    "                    g_eff=g_eff,\n",
    "                )\n",
    "                \n",
    "    # Save\n",
    "    H_YX_pred_all[md5_ref] = H_YX_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dc721f-5f1f-4ddf-b0c6-19921161cd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattenlist(lst):\n",
    "    return [item for sublist in lst for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0f1a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outer iterator over the different ground truth datasets\n",
    "T = [2000, 2200]\n",
    "tstop = params.networkParameters['tstop']\n",
    "dt = params.networkParameters['dt']\n",
    "markersize = 8\n",
    "\n",
    "fig = plt.figure(figsize=(figwidth, figwidth / golden_ratio))\n",
    "gs = GridSpec(5, 5, left=0.05, right=0.95, bottom=0.1, top=0.95, wspace=0.4, hspace=1)\n",
    "gs2 = GridSpec(5, 3, left=0.05, right=0.95, bottom=0.1, top=0.95, wspace=0.4, hspace=1)\n",
    "axes = [[], [], []]\n",
    "for hh in range(PS_ref.num_conditions()):\n",
    "    # rasters panels:\n",
    "    if hh == 0:\n",
    "        ax = fig.add_subplot(gs[0, hh])\n",
    "    else:\n",
    "        ax = fig.add_subplot(gs[0, hh], sharex=axes[0][0], sharey=axes[0][0])\n",
    "    axes[0].append(ax)\n",
    "\n",
    "for hh in range(3):\n",
    "    axes[1].append(fig.add_subplot(gs2[1:3, hh]))\n",
    "    axes[2].append(fig.add_subplot(gs2[3:, hh]))\n",
    "    \n",
    "for ax in flattenlist(axes):\n",
    "    remove_axis_junk(ax)\n",
    "\n",
    "annotate_subplot(axes[0][0], ncols=5, nrows=5, letter='A', linear_offset=0.02)\n",
    "annotate_subplot(axes[1][0], ncols=3, nrows=5/1.5, letter='B', linear_offset=0.02)\n",
    "\n",
    "for i, ax in enumerate(axes[1][1:]):\n",
    "    annotate_subplot(ax, ncols=3, nrows=5/1.5, letter='CD'[i], linear_offset=0.02)\n",
    "for i, ax in enumerate(axes[2][1:]):\n",
    "    annotate_subplot(ax, ncols=3, nrows=5/1.5, letter='EF'[i], linear_offset=0.02)\n",
    "\n",
    "\n",
    "# container\n",
    "df = pd.DataFrame(columns=['R2', 'STD/STD', 'weight_scaling', 'probe', 'signal', 'channel'])\n",
    "    \n",
    "for hh, pset_ref in enumerate(PS_ref.iter_inner()):\n",
    "    js_ref = json.dumps(pset_ref, sort_keys=True).encode()\n",
    "    md5_ref = hashlib.md5(js_ref).hexdigest()\n",
    "    OUTPUTPATH_REF = os.path.join('output', md5_ref)\n",
    "    print(OUTPUTPATH_REF, os.path.isdir(OUTPUTPATH_REF))\n",
    "    \n",
    "    # plot spike raster\n",
    "    ax = axes[0][hh]\n",
    "    if hh >= 0:\n",
    "        ax.set_ylabel('gid')  \n",
    "    else:\n",
    "        plt.setp(ax.get_yticklabels(), visible=False)\n",
    "    \n",
    "    title = f\"$J={pset_ref['weight_scaling']}$\\n\"\n",
    "    with h5py.File(os.path.join(OUTPUTPATH_REF, 'spikes.h5'), 'r') as f:\n",
    "        for i, y in enumerate(population_names):\n",
    "            times = []\n",
    "            gids = []\n",
    "\n",
    "            for g, t in zip(f[y]['gids'], f[y]['times']):\n",
    "                times = np.r_[times, t]\n",
    "                gids = np.r_[gids, np.zeros(t.size) + g]\n",
    "\n",
    "            gids = gids[times >= TRANSIENT]\n",
    "            times = times[times >= TRANSIENT]\n",
    "\n",
    "            ii = (times >= T[0]) & (times <= T[1]) & (gids >= -np.diff(population_sizes))\n",
    "            ax.plot(times[ii], gids[ii], '.',\n",
    "                    mfc=colors[i],\n",
    "                    mec='none',\n",
    "                    ms=2,\n",
    "                    label=r'$\\langle \\nu_\\mathrm{%s} \\rangle =%.2f$ s$^{-1}$' % (\n",
    "                        y, times.size / f[y]['gids'].size /\n",
    "                        (tstop - TRANSIENT) * 1000))\n",
    "            title = title + r'$\\langle \\nu_\\mathrm{%s} \\rangle =%.1f$ s$^{-1}$' % (\n",
    "                        y, times.size / f[y]['gids'].size /\n",
    "                        (tstop - TRANSIENT) * 1000)\n",
    "            if i == 0:\n",
    "                title = title + '\\n'\n",
    "    ax.set_title(title)\n",
    "    # ax.legend(loc='upper right')\n",
    "    ax.axis('tight')\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel('t (ms)')\n",
    "    if hh == 0:\n",
    "        ax.set_ylabel('gid')  \n",
    "    else:\n",
    "        plt.setp(ax.get_yticklabels(), visible=False)\n",
    "        ax.set_ylabel('')\n",
    "    \n",
    "    \n",
    "    # compute firing rate time series of \"real\" network\n",
    "    tstop = networkParameters['tstop']\n",
    "    nu_X, bins = methods.compute_nu_X(os.path.join(OUTPUTPATH_REF, 'spikes.h5'), population_names, \n",
    "                                           T=(0, tstop), Delta_t=dt)\n",
    "            \n",
    "    # plot rate spectra summing E and I spikes\n",
    "    for i, X in enumerate(population_names):\n",
    "        nu = nu_X[X] / (dt / 1000)\n",
    "\n",
    "        nu = nu[int(TRANSIENT // dt):]\n",
    "        w = pset_ref['weight_scaling']\n",
    "        if w == 1.:\n",
    "            color = 'k'\n",
    "        else:\n",
    "            color = f'C{hh}'    \n",
    "        freqs, Pxx = ss.welch(nu, fs=Fs, nperseg=NFFT, noverlap=noverlap, detrend=detrend)\n",
    "        ax = axes[i + 1][0]\n",
    "        ax.loglog(freqs[freqs <= freqs_cutoff], Pxx[freqs <= freqs_cutoff],\n",
    "                    color=color,\n",
    "                    label=f'$J={w}$')\n",
    "        ax.axis(ax.axis('tight'))\n",
    "        if i==0:\n",
    "            ax.legend(loc='upper right')\n",
    "            plt.setp(ax.get_xticklabels(), visible=False)\n",
    "        else:\n",
    "            ax.set_xlabel('$f$ (Hz)')\n",
    "        ax.set_ylabel(r'$S_{\\nu_' + f'{X}' + r'\\nu_' + f'{X}' + r'}$ (s$^{-2}$/Hz)')\n",
    "\n",
    "        # find local maxima\n",
    "        inds = (freqs > 10) & (freqs < 100)\n",
    "        print(f\"J={pset_ref['weight_scaling']}; pop:{X}; fmax={freqs[inds][Pxx[inds] == Pxx[inds].max()]}\")\n",
    "\n",
    "    \n",
    "    # compute and show R2 and STD ratio between ground truth and prediction\n",
    "    for j, (fname, ylabel, probe, unit, vlimround) in enumerate(zip(\n",
    "            ['RecExtElectrode.h5', 'CurrentDipoleMoment.h5'],\n",
    "            [r'$V_\\mathrm{e}$', r'$\\mathbf{P}$'],\n",
    "            ['GaussCylinderPotential', 'CurrentDipoleMoment'],\n",
    "            ['mV', 'nAÂµm'],\n",
    "            [2**-1, 2**18])):\n",
    "        with h5py.File(os.path.join(OUTPUTPATH_REF, fname),\n",
    "                       'r') as f:\n",
    "            data_ref = f['data'][()]['E']\n",
    "        \n",
    "        # low pass filter, remove startup transient\n",
    "        data_ref_lp = ss.sosfiltfilt(sos_ellip, data_ref)[:, int(TRANSIENT // dt):]\n",
    "        data_ref = data_ref[:, int(TRANSIENT // dt):]\n",
    "\n",
    "        # Compute reconstructed signals as the sum over convolutions\n",
    "        # phi(r, t) = sum_X sum_Y (nu_X*H_YX)(r, t)\n",
    "        for k, pset in enumerate(PS2.iter_inner()):\n",
    "            pset['weight_scaling'] = pset_ref['weight_scaling']  # use reference value!\n",
    "            \n",
    "            # sorted json dictionary\n",
    "            js = json.dumps(pset, sort_keys=True).encode()\n",
    "            md5 = hashlib.md5(js).hexdigest()\n",
    "            \n",
    "            # signal container\n",
    "            data = None\n",
    "\n",
    "            for i, (X, N_X) in enumerate(zip(population_names,\n",
    "                                             population_sizes)):\n",
    "                for Y in ['E']: # population_names:\n",
    "                    if data is None:\n",
    "                        data = np.zeros((H_YX_pred_all[md5_ref][md5]['{}:{}'.format(Y, X)][probe].shape[0],\n",
    "                                         nu_X[X].size))\n",
    "                    for h, h_YX in enumerate(H_YX_pred_all[md5_ref][md5]['{}:{}'.format(Y, X)][probe]):\n",
    "                        data[h, :] = data[h, :] + np.convolve(nu_X[X], h_YX,\n",
    "                                                              'same')\n",
    "            # low-pass filter, remove startup transient\n",
    "            data_lp = ss.sosfiltfilt(sos_ellip, data)[:, int(TRANSIENT // dt):]\n",
    "            data = data[:, int(TRANSIENT // dt):]\n",
    "            \n",
    "            # number of channels\n",
    "            n_ch = data.shape[0]\n",
    "\n",
    "            # Pearson correlation coefficients\n",
    "            Pcc = np.corrcoef(data_ref, data)[n_ch:, :n_ch].diagonal()\n",
    "            Pcc_lp = np.corrcoef(data_ref_lp, data_lp)[n_ch:, :n_ch].diagonal()\n",
    "\n",
    "            # STD(y) / STD(x)\n",
    "            scaling = data.std(axis=-1) / data_ref.std(axis=-1)\n",
    "            scaling_lp = data_lp.std(axis=-1) / data_ref_lp.std(axis=-1)\n",
    "\n",
    "            for ch in range(n_ch):\n",
    "                df = df.append([\n",
    "                        pd.DataFrame(\n",
    "                            data={'R2': Pcc[ch]**2, 'STD/STD': scaling[ch], \n",
    "                                  'weight_scaling': pset_ref['weight_scaling'], \n",
    "                                  'probe': probe,\n",
    "                                  'signal': 'raw', 'channel': (ch + 1)}, \n",
    "                            index=[0]\n",
    "                        ),\n",
    "                        pd.DataFrame(\n",
    "                            data={'R2': Pcc_lp[ch]**2, 'STD/STD': scaling_lp[ch], \n",
    "                                  'weight_scaling': pset_ref['weight_scaling'], \n",
    "                                  'probe': probe,\n",
    "                                  'signal': 'LP', 'channel': (ch + 1)}, \n",
    "                            index=[0]\n",
    "                        ),\n",
    "                        ],\n",
    "                    ignore_index=True)\n",
    "            \n",
    "            # plot\n",
    "            w = pset_ref['weight_scaling']\n",
    "            if w == 1.:\n",
    "                color = 'k'\n",
    "            else:\n",
    "                color = f'C{hh}'\n",
    "            if probe == 'CurrentDipoleMoment':\n",
    "                ax = axes[2][2]\n",
    "                \n",
    "                ax.plot(Pcc[2]**2, scaling[2], 'o', mec=color, mfc=color, ms=markersize, \n",
    "                        label=f'$J={w}$; raw', clip_on=False)\n",
    "                ax.plot(Pcc_lp[2]**2, scaling_lp[2], 'o', mec=color, mfc='w', ms=markersize, \n",
    "                        label=f'$J={w}$; LP', clip_on=False)\n",
    "                # ax.set_ylabel(r'$r_\\mathrm{STD}$')\n",
    "                ax.set_xlabel(r'$R^2$ (-)')\n",
    "            else:\n",
    "                ax = axes[1][1]\n",
    "\n",
    "                ax.plot(Pcc**2, np.arange(n_ch) + 1, '-o', color=color, ms=markersize, \n",
    "                        label=f'$J={w}$; raw', clip_on=False)\n",
    "                ax.plot(Pcc_lp**2, np.arange(n_ch) + 1, '-o', color=color, mfc='w', ms=markersize, \n",
    "                        label=f'$J={w}$; LP', clip_on=False)\n",
    "                ax.set_xlabel(r'$R^2$ (-)')\n",
    "                # ax.set_xlim(xmax=1)\n",
    "\n",
    "                ax = axes[1][2]\n",
    "                ax.plot(scaling, np.arange(n_ch) + 1, '-o', color=color, ms=markersize, clip_on=False)\n",
    "                ax.plot(scaling_lp, np.arange(n_ch) + 1, '-o', color=color, mfc='w', ms=markersize, clip_on=False)\n",
    "                ax.set_xlabel(r'$r_\\mathrm{STD}$')\n",
    "\n",
    "                for ax in axes[1][1:]:\n",
    "                    ax.set_yticks(np.arange(n_ch) + 1)\n",
    "                    ax.set_yticklabels(['ch.{}'.format(i + 1) for i in np.arange(n_ch)])\n",
    "                plt.setp(axes[1][2].get_yticklabels(), visible=False)\n",
    "\n",
    "                axes[1][2].vlines(1, 1, n_ch, ls=':')\n",
    "                \n",
    "df_agg = df.groupby(['signal', 'weight_scaling', 'probe'], as_index=False\n",
    "                    ).agg({'R2': ['mean', 'median', methods.quant10, methods.quant90], \n",
    "                           'STD/STD': ['mean', 'median', methods.quant10, methods.quant90]})\n",
    "\n",
    "ax = axes[2][1]\n",
    "markers = 'o'\n",
    "weight_scaling = list(PS0['weight_scaling'])\n",
    "probe = 'GaussCylinderPotential'\n",
    "for i, weight in enumerate(weight_scaling):\n",
    "    for j, signal in enumerate(['raw', 'LP']):        \n",
    "        d = df_agg[(df_agg['weight_scaling'] == weight) & \n",
    "                   (df_agg['signal'] == signal) & \n",
    "                   (df_agg['probe'] == probe)]\n",
    "        color = f'C{i}' if weight != 1. else 'k'\n",
    "        ax.errorbar(x=d['R2']['median'], \n",
    "                    y=d['STD/STD']['median'],\n",
    "                    xerr=np.c_[d['R2']['median'] - d['R2']['quant10'], \n",
    "                               d['R2']['quant90'] - d['R2']['median']].T,\n",
    "                    yerr=np.c_[d['STD/STD']['median'] - d['STD/STD']['quant10'], \n",
    "                               d['STD/STD']['quant90'] - d['STD/STD']['median']].T,\n",
    "                    fmt=markers, \n",
    "                    ms=markersize,\n",
    "                    ecolor=color,\n",
    "                    mec=color,\n",
    "                    mfc='w' if signal == 'LP' else color,\n",
    "                    label=weight_scaling if j == 0 else '_nolegend_')\n",
    "ax.set_ylabel(r'$r_\\mathrm{STD}$')\n",
    "ax.set_xlabel('$R^2$')\n",
    "\n",
    "\n",
    "for ax in axes[1][1:]:\n",
    "    ax.invert_yaxis()\n",
    "for ax in [axes[1][1], axes[2][2]]:\n",
    "    ax.legend(loc='best')\n",
    "    # ax.legend(loc='upper right', bbox_to_anchor=(1, 1))\n",
    "\n",
    "fig.savefig('figures/figure11_Hay.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f66668",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3d9169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregated mean and standard deviations etc. of R2 and STD ratio\n",
    "df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec04e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
